<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Christian Engels&#x27; Homepage - TCS</title>
    <subtitle>Homepage of Christian Engels</subtitle>
    <link rel="self" type="application/atom+xml" href="https://narfinger.github.io/categories/tcs/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://narfinger.github.io/"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2023-04-27T01:00:00+00:30</updated>
    <id>https://narfinger.github.io/categories/tcs/atom.xml</id>
    <entry xml:lang="en">
        <title>Reading March</title>
        <published>2023-04-27T01:00:00+00:30</published>
        <updated>2023-04-27T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2023/readingv2/"/>
        <id>https://narfinger.github.io/posts/2023/readingv2/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2023/readingv2/">&lt;h1 id=&quot;paper-1&quot;&gt;Paper 1&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2021&#x2F;100&#x2F;&quot;&gt;Ikenmeyer, Komarath, Saurabh - Karchmer-Wigderson Games for Hazard Free Circuits&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;$u$ defines the unknown state.&lt;&#x2F;li&gt;
&lt;li&gt;A resolution of a string in ${0,1,u}^*$ is a setting of the undefined values to an arbitrary value in ${0,1}$.&lt;&#x2F;li&gt;
&lt;li&gt;We can define $\bar f(\alpha)$ to be $0$ or $1$ if the value for all resolutions is zero or one. Otherwise it is defined as $u$.&lt;&#x2F;li&gt;
&lt;li&gt;A circuit is called hazard free if $C(\alpha)=\bar f(\alpha)$ for all $\alpha \in {0,1,u}^n$.&lt;&#x2F;li&gt;
&lt;li&gt;Define $MUX_n(s_1,\dots,s_n, x_{0,0,...,0},\dots, x_{1,...,1})=x_{s_1,\dots,s_n}$.&lt;&#x2F;li&gt;
&lt;li&gt;They give an exact bound on the size of the hazard free circuit for MUX$_n$.&lt;&#x2F;li&gt;
&lt;li&gt;$size(MUX_n)=23^n -1$.&lt;&#x2F;li&gt;
&lt;li&gt;They use Karchmer Wigderson game on subcube intersection game for this.&lt;&#x2F;li&gt;
&lt;li&gt;Define $d f(x;y)=1$ if and only if $\bar f(x\oplus u \cdot y)=u$, meaning there is a resolution to one and one to zero.&lt;&#x2F;li&gt;
&lt;li&gt;For any hazard free circuit and any boolean string $a$, we can construct a monotone circuit for $df(a;y)$. Hence, this gives us lower bounds.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;karchmer-widgerson-relationships&quot;&gt;Karchmer Widgerson Relationships&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Alice has $a$ with $f(a)=1$ and Bob has $b$ with $f(b)=0$. Find a coordinate such that $a_i\neq b_i$.&lt;&#x2F;li&gt;
&lt;li&gt;Their extension: Alice gets $\alpha$, Bob $\beta$ with $\bar f(\alpha)=1$, $\bar f(\beta)=0$. Determine a coordinate such that $\alpha_i\neq \beta_i$ &lt;em&gt;and&lt;&#x2F;em&gt; $\alpha_i\neq u$, $\beta_i\neq u$.&lt;&#x2F;li&gt;
&lt;li&gt;A prime implicant is an $\alpha \in f^{-1}(1)$ such that no value from ${0,1}$ can be replaced by an $u$.&lt;&#x2F;li&gt;
&lt;li&gt;Elements in $f^{-1}(0)$ are called implicates.&lt;&#x2F;li&gt;
&lt;li&gt;It is enough to look at the implicants and implicates as inputs to the game.
&lt;ul&gt;
&lt;li&gt;By flipping stable bits, we get the opposite, hence, it is enough for Alice and Bob.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;For a monotone function, the complexity between the extension game and the monotone game are the same.
&lt;ul&gt;
&lt;li&gt;This is easy to see. Alice flips $u$s up (to 1) and Bob down. Because of monotonicity the value is the still the same.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The Multiplexer function is now an obvious candidate.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Reading January</title>
        <published>2023-01-24T01:00:00+00:30</published>
        <updated>2023-01-24T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2023/reading/"/>
        <id>https://narfinger.github.io/posts/2023/reading/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2023/reading/">&lt;h1 id=&quot;paper-1&quot;&gt;Paper 1&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.05970v3&quot;&gt;Golovnev, Gur, Shinkar - Derandomization of Cell Sampling&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;result&quot;&gt;Result&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Previously there was a problem on $n$ inputs and $m$ possible queries:
&lt;ul&gt;
&lt;li&gt;Such that any data structure that answers queries by probing $t$ memory cells requires space $s\geq \tilde \Omega(n (m&#x2F;n)^{1&#x2F;t})$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This paper improves this to $s\geq \tilde\Omega(n (m&#x2F;n)^{1&#x2F;(t-1)})$ for $t\geq 2$ for non-adaptive data structures.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Theorem: Let $G$ be a large enough $t$-hypergraph with at least $|V| (1+\epsilon)$ edges for large enough $\epsilon$. If $|E| \geq 3|V|\left( \frac{2^{t+3} |V| \log |V|}{k}\right)^{t-2}$ for $2^{t+2}\log |V| \leq k \leq |V|$. Then there exists a subset $S$ of size $|S|\leq k$ that spans at least $|S| + \frac{k}{2^{t+1}\log s}$ hyperedges.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;how-to-use-this-to-get-the-data-structure-lower-bound&quot;&gt;How to use this to get the data structure lower bound?&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;A function $f:F^n \rightarrow F^m$ is called $k$-wise independent if for every possible output $S$ the uniform distribution of the $n$ inputs induces the uniform distribution of the outputs.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;We build a data structure for the $k$-wise independent problem.&lt;&#x2F;li&gt;
&lt;li&gt;We need to read at least $k$ memory cells.&lt;&#x2F;li&gt;
&lt;li&gt;For $t=2$ construct a multigraph with $s$ vertices corresponding to the memory cells.&lt;&#x2F;li&gt;
&lt;li&gt;Each edge will be a pair of cells read for a query.&lt;&#x2F;li&gt;
&lt;li&gt;Then by the graph theorem, there exists a set of $k$ queries that depend on $k-1$ memory cells.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, it must satisfy that $s\geq m&#x2F;(1+16 \log s &#x2F;k)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-2&quot;&gt;Paper 2&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2301.05658&quot;&gt;Lovett, Zhang - Streaming Lower Bounds and Asymmetric Set-Disjointness&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;result-1&quot;&gt;Result&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Needle problem: $t$, number of samples, $n$ universe size, $p$ probability of needle.&lt;&#x2F;li&gt;
&lt;li&gt;Distinguish in a streaming setting with $s$ space the following two distributions:
&lt;ul&gt;
&lt;li&gt;Uniformly sampled from $[n]$.&lt;&#x2F;li&gt;
&lt;li&gt;Sample each with probability $p$ to be the needle $x\in [n]$ and with $1-p$ sample uniformly from $[n]$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;We assume with high probability all elements are unique by setting $n=\Omega(t^2)$.&lt;&#x2F;li&gt;
&lt;li&gt;$p=\Omega(1&#x2F;t)$ as otherwise the distributions are too close.&lt;&#x2F;li&gt;
&lt;li&gt;Algorithms examples:
&lt;ul&gt;
&lt;li&gt;Test if two adjacent elements are equal.
&lt;ul&gt;
&lt;li&gt;$t=\Omega(1&#x2F;p^2)$ samples and space $\Theta(\log n)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Store the entrie stream in memory and check for repeated elements.
&lt;ul&gt;
&lt;li&gt;$t=\Theta(1&#x2F;p)$ but space $s=t\log n$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;&lt;em&gt;Conjecture&lt;&#x2F;em&gt;: Any single-pass streaming algorithm which can solve the needle problem satisfies $p^2st=\Omega(1)$.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;em&gt;Result&lt;&#x2F;em&gt;: Any $l$ pass streaming algorithm satisfies $lp^2st\log t = \Omega(1)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-aproach&quot;&gt;Proof Aproach&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Reduction to unique set disjointness in communication complexity.&lt;&#x2F;li&gt;
&lt;li&gt;Partition the stream into intervals $I_1,\dots,I_k$.&lt;&#x2F;li&gt;
&lt;li&gt;Any streaming algorithm can be transformed into a communication protocol that solves the $k$-party unqiue set disjointness.&lt;&#x2F;li&gt;
&lt;li&gt;This requires one needle per interval.&lt;&#x2F;li&gt;
&lt;li&gt;The rest of the paper is devoted to fixing this.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-3&quot;&gt;Paper 3&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;link.springer.com&#x2F;chapter&#x2F;10.1007&#x2F;3-540-48447-7_18&quot;&gt;Benoit, Demaine, Munro, Raman, Raman, Rao-Representing Trees of Higher Degree&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;The lower bound for $k$-ary trees is $\log C_n^k = nk\log k -n(k-1)\log (k-1) - O(\log kn)$.&lt;&#x2F;li&gt;
&lt;li&gt;Their bound is $n\log k + n\log e$ (for a slowly growing function of $k(n)$).
&lt;ul&gt;
&lt;li&gt;This answers queries of parent, $i$th child, subtree size in constant time.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;There exists a data structure of size $\log C_n^k + o(n+\log k)$. &lt;a href=&quot;https:&#x2F;&#x2F;narfinger.github.io&#x2F;posts&#x2F;2023&#x2F;reading&#x2F;#Paper-4&quot;&gt;See Paper 4&lt;&#x2F;a&gt;
&lt;ul&gt;
&lt;li&gt;This answers queries of parent, $i$th child with constant time and subtree size needs more time.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;What strikes me odd is that it seems difficult to store labels in the tree and access this label efficiently.
&lt;ul&gt;
&lt;li&gt;While some of this can be fixed it is unclear how to keep the query time for this constant.&lt;&#x2F;li&gt;
&lt;li&gt;Take for example, storing the labels in an array with the order of the vertices being the index in the label.&lt;&#x2F;li&gt;
&lt;li&gt;Getting from the an arbitrary node to the parent of the child takes probably the subtree encoding which is non constant in the optimal way.&lt;&#x2F;li&gt;
&lt;li&gt;But I am not sure.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-1&quot;&gt;Proof&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Jacobson Ordinal tree encoding:
&lt;ul&gt;
&lt;li&gt;Represent a node of degree $d$ by $1^d0$.&lt;&#x2F;li&gt;
&lt;li&gt;Write them in a level order traversal for the entire treee.&lt;&#x2F;li&gt;
&lt;li&gt;This needs rank and select to answer child queries.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Munro and Raman encoding:
&lt;ul&gt;
&lt;li&gt;Isomorphism with Ordinal tree (ordered trees). Use now a balanced parenthesis encoding.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This encoding: Write the unary degree encoding in DFS order.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-4&quot;&gt;Paper 4&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;0705.0552&quot;&gt;Raman, Raman, Satti - Succinct Indexable Dictionaries with Applications to Encoding k-ary Trees, Prefix Sums and Multisets&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-5&quot;&gt;Paper 5&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;people.unipmn.it&#x2F;manzini&#x2F;papers&#x2F;focs05.pdf&quot;&gt;Ferragina, Luccio, Manzini, Muthukrishnan-Structuring labeled trees for optimal succinctness and beyond&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;This should allowe trees with arbitrary labels and the operations you want with almost optimal encoding.&lt;&#x2F;li&gt;
&lt;li&gt;They define the following transcoding:
&lt;ul&gt;
&lt;li&gt;Let $t=n+l$ where $n$ is the number of &lt;em&gt;internal&lt;&#x2F;em&gt; nodes and $l$ the size of the labels.&lt;&#x2F;li&gt;
&lt;li&gt;Visit $T$ in pre-order and create for a vertex $u$: $(\text{last}(u), \alpha(u),\pi(u))$.
&lt;ul&gt;
&lt;li&gt;$\text{last}(u)$ is the binary flag if it is the last child of the parent.&lt;&#x2F;li&gt;
&lt;li&gt;$\pi(u)$ is the string obtained by concatenating the symbols on the upward path to the root.&lt;&#x2F;li&gt;
&lt;li&gt;$\alpha(u)$ is the label of $u$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Stable Sort this lexicographically according to $\pi(u)$.&lt;&#x2F;li&gt;
&lt;li&gt;Let this array be called $S$ and let us call $S_\text{last}$ to call the projection to the first part of the tuple.&lt;&#x2F;li&gt;
&lt;li&gt;$S_\text{last}$ has $n$ bits set to one.
&lt;ul&gt;
&lt;li&gt;I do not quite understand this. The upper bound is true but not every internal node is the last node of a parent.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The other bits are set to zero.&lt;&#x2F;li&gt;
&lt;li&gt;$S_\alpha$ contains all the labels of the nodes.&lt;&#x2F;li&gt;
&lt;li&gt;$S_\pi$ contains all the upward labelled paths of $T$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we can find the following structure which comes from the sorting:
&lt;ul&gt;
&lt;li&gt;The first tuple is the root.&lt;&#x2F;li&gt;
&lt;li&gt;If $u,u&#x27;$ are two nodes with $\pi(u)=\pi(u&#x27;)$. Then they have the same depth and $u$ is to the left of $u&#x27;$ if it preceeds it.&lt;&#x2F;li&gt;
&lt;li&gt;The children of a node $u_1,\dots,u_c$ lie continuously in the array and the last one has the bit set to one.&lt;&#x2F;li&gt;
&lt;li&gt;Let $u,u&#x27;$ be two nodes in $T$. If they preceed in the array they preceeded in the tree.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;For navigation we need rank and select.
&lt;ul&gt;
&lt;li&gt;Rank$_c(1,q)$ is the number of times c appears in $S[1..q]$.&lt;&#x2F;li&gt;
&lt;li&gt;select$_c(S,q)$ is the position of the $q$th occurence of $c$ in $S$.&lt;&#x2F;li&gt;
&lt;li&gt;These queries can be done with constant time using $\log \binom{|S|}{m} + o(m) + O(\log \log s)$ where $m$ is the number of ones.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Navigation on this array.
&lt;ul&gt;
&lt;li&gt;GetChildren(i)
&lt;ul&gt;
&lt;li&gt;Get the label of the current node.&lt;&#x2F;li&gt;
&lt;li&gt;Find the first occurrence of this label (this is now the first child).&lt;&#x2F;li&gt;
&lt;li&gt;Find where the one is for this block of children.&lt;&#x2F;li&gt;
&lt;li&gt;The in between are now all the children of $i$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;GetParent(i)
&lt;ul&gt;
&lt;li&gt;Find the symbol of the parent.&lt;&#x2F;li&gt;
&lt;li&gt;Compute the offset.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-6&quot;&gt;Paper 6&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;link.springer.com&#x2F;content&#x2F;pdf&#x2F;10.1007&#x2F;3-540-48447-7_34.pdf&quot;&gt;Brodal, Faderberg - Dynamic Representations of Sparse Graphs&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Arboricity of a graph is given as $\max_J \frac{\lvert E(J)\rvert}{\lvert V(J)-1\rvert}$ for any subgraph $J$ with $\lvert V(J)\rvert\geq 2$.&lt;&#x2F;li&gt;
&lt;li&gt;This contains graph of bounded treewidth, planar and bounded genus.&lt;&#x2F;li&gt;
&lt;li&gt;Operations on the data structure:
&lt;ul&gt;
&lt;li&gt;Adjacent(u,v) =&amp;gt; true if $(u,v)\in E$&lt;&#x2F;li&gt;
&lt;li&gt;Insert(u,v) =&amp;gt; $E= (u,v)\cup E$&lt;&#x2F;li&gt;
&lt;li&gt;Delete(u,v) =&amp;gt; $E = E\setminus (u,v)$&lt;&#x2F;li&gt;
&lt;li&gt;Build(G) =&amp;gt; Construct the data structure.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Data structure uses $O(m+n)$ space and supports queries in adjacent in worst case $O(c)$, Insert in armortized $O(1)$ and Delete in armortized $O(c+\log n)$ where c is the arboricity of the graph.&lt;&#x2F;li&gt;
&lt;li&gt;Arboricity needs to be known.&lt;&#x2F;li&gt;
&lt;li&gt;The data structure is a simple adjacency list where we assign an orientation to every edge such that every vertex has outdegree $O(c)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-7&quot;&gt;Paper 7&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;(Raman, Raman, Rao - Succinct Dynamic Data Structures)[https:&#x2F;&#x2F;www.imsc.res.in&#x2F;~vraman&#x2F;pub&#x2F;wads_01.pdf]&lt;&#x2F;li&gt;
&lt;li&gt;Solving Dynamic Data Structures for Partial Sums and Arrays&lt;&#x2F;li&gt;
&lt;li&gt;Partial sums solved with $kn+o(n)$ space and time $O(\log n&#x2F;\log \log n)$ with $k$ being the logarithm of the size of the entries.&lt;&#x2F;li&gt;
&lt;li&gt;Array uses $o(n)$ extra space with $O(\log n&#x2F;\log \log n)$ operation time.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;paper-8&quot;&gt;Paper 8&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;(Chung, Larsen - Stronger 3SUM Indexing Lower bounds)[http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.09334v1]&lt;&#x2F;li&gt;
&lt;li&gt;3SUM:
&lt;ul&gt;
&lt;li&gt;Given an abelian group $G$ and and two subsets of group elements $A_1,A_2$ does there for a given $z$ exists $a_1 +a_2=z$ with $a_1\in A_1, a_2\in A_2$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;There exists various hardness conjectures for this problem.&lt;&#x2F;li&gt;
&lt;li&gt;Old Theorem:
&lt;ul&gt;
&lt;li&gt;Any non-adaptive data structure for 3SUM using $S$ words of size $w$ must have query time $T=\Omega(\lg n&#x2F;\lg (Sw&#x2F;n))$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The make this theorem work for adaptive data structures.&lt;&#x2F;li&gt;
&lt;li&gt;Proof by reduction to butterfly graphs.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-2&quot;&gt;Proof&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Butterfly graph:
&lt;ul&gt;
&lt;li&gt;$d+1$ layers each having $B^d$ nodes.&lt;&#x2F;li&gt;
&lt;li&gt;We look at a layer as a $d$ digit number in base $B$.&lt;&#x2F;li&gt;
&lt;li&gt;Every vertex has the label of its number in $B$-ary representation.&lt;&#x2F;li&gt;
&lt;li&gt;There is an edge from $i$ to $j$ if $i$ and $j$ differ only on the $k$th digit.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;For any source sink pair there exists a unique path.
&lt;ul&gt;
&lt;li&gt;This is easy to see. Otherwise, we would have two paths which flip different bits which can never be unflipped.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Butter fly graph reachability has the following lower bound
&lt;ul&gt;
&lt;li&gt;$T=\Omega(d)$, then $B=\Omega(w^2)$ and $\lg(B) =\Omega(\lg (Sd&#x2F;dB^d)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Construction of 3SUM reduction, i.e., given a butterfly graph, construct a 3SUM query:
&lt;ul&gt;
&lt;li&gt;$A_1$:
&lt;ul&gt;
&lt;li&gt;The digits will be broken into 5 blocks.&lt;&#x2F;li&gt;
&lt;li&gt;First block encodes the layer the edge is from.&lt;&#x2F;li&gt;
&lt;li&gt;Second block encodes the presence of the edge $e(i,j)$ in layer $k$.&lt;&#x2F;li&gt;
&lt;li&gt;Third block encodes the $d-k$ most significant bits of $i$ followed by $k$ zeroes.&lt;&#x2F;li&gt;
&lt;li&gt;Fourth block encodes the $d-k-1$ zeroes followed by $k+1$ least significant digits of $j$.&lt;&#x2F;li&gt;
&lt;li&gt;Fifth block holds 2 zeroes.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;$A_2$:
&lt;ul&gt;
&lt;li&gt;First block holds some value $-k$.&lt;&#x2F;li&gt;
&lt;li&gt;Second block is zero.&lt;&#x2F;li&gt;
&lt;li&gt;Third block is $d-k$ zeroes followed by any possible $k$ digit value.&lt;&#x2F;li&gt;
&lt;li&gt;Fourth block holds any possible $d-k-1$ digit value followed by $k+1$ zeroes.&lt;&#x2F;li&gt;
&lt;li&gt;Fifth block holds any possible digit from $[0,B-1]$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Translting Reachability Query:
&lt;ul&gt;
&lt;li&gt;First notice that carries do not matter here.
&lt;ul&gt;
&lt;li&gt;A lot of the construction needs to make sure and that is why there are certain zeroes.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;If there does not exist a path then there is an edge missing.&lt;&#x2F;li&gt;
&lt;li&gt;Then there is just all the parts fit together.&lt;&#x2F;li&gt;
&lt;li&gt;If there does exist a path and all have 1 at the second place.&lt;&#x2F;li&gt;
&lt;li&gt;This can never be made into a value zero at the second place.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;non-adaptive-bit-probe-3sum-lower-bound&quot;&gt;Non Adaptive Bit Probe 3SUM Lower Bound&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Lower bound of $\Omega(\min { \lg |G|, \lg (Sw&#x2F;n), n&#x2F;w})$.&lt;&#x2F;li&gt;
&lt;li&gt;Let $\Delta = n&#x2F;2w$.&lt;&#x2F;li&gt;
&lt;li&gt;By an averaging counting argument there is a set of cells answering at least $|G| \binom{S-T}{\Delta-T}&#x2F; \binom{S}{\Delta}$ queries.&lt;&#x2F;li&gt;
&lt;li&gt;Now assume $T\leq \Delta&#x2F;2$ as otherwise we are done.&lt;&#x2F;li&gt;
&lt;li&gt;This is at least $|G|^{1-o(1)} &amp;gt; n$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we will prove that the queries cannot be answered from such few cells for a given distribution over $A_1,A_2$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma: There exists an input distribution for which the event of any element in a subset $Q$ being included in the sum $A_1 +A_2$ is fully independent.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us an entropy of $n$.&lt;&#x2F;li&gt;
&lt;li&gt;But these cells chosen above have are $n&#x2F;2w$ having $n&#x2F;2$ bits.&lt;&#x2F;li&gt;
&lt;li&gt;As their addresses are fixed this gives us a contradiction.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Correlation bounds against polynomials</title>
        <published>2022-12-22T01:00:00+00:30</published>
        <updated>2022-12-22T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/correlation-survey/"/>
        <id>https://narfinger.github.io/posts/2022/correlation-survey/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/correlation-survey/">&lt;h1 id=&quot;paper&quot;&gt;Paper&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2022&#x2F;142&#x2F;&quot;&gt;Viola - Correlation bounds against polynomials&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;correlation-bounds&quot;&gt;Correlation Bounds&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Notice that things like AND (which has large degree) easy correlation (the all zero polynomia).&lt;&#x2F;li&gt;
&lt;li&gt;Cor_D(f,p) = $\lvert \Pr_{x\sim D}[f(x)=p(x)] - \Pr_{x\sim D}[f(x)\neq p(x)]\rvert$&lt;&#x2F;li&gt;
&lt;li&gt;Cor_D(f,d) = $\max_p Cor_D(f,p)$.&lt;&#x2F;li&gt;
&lt;li&gt;Open Question:
&lt;ul&gt;
&lt;li&gt;Is there an $f$ such that $Cor_D(f,\log n) \leq 1&#x2F;\sqrt{n}$?&lt;&#x2F;li&gt;
&lt;li&gt;Notice that this is a hardness.&lt;&#x2F;li&gt;
&lt;li&gt;It asks for a hard $f$ that with $\log n$ degree can only be barely simulated.&lt;&#x2F;li&gt;
&lt;li&gt;A negative answer to this would imply that NP circuits have quasi polynomial size (non-trivial but easy with right techniques).&lt;&#x2F;li&gt;
&lt;li&gt;Notice that this says nothing about how easy the polynomial is to compute (algebraic sense) or how many monomials it has.&lt;&#x2F;li&gt;
&lt;li&gt;This question also related to number-on-forehead communication complexity.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Algebrazation is not a barrier because of non-uniformity.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;bound-1-degree-log-n-but-correlation-epsilon-1-n&quot;&gt;Bound 1: degree &amp;gt;&amp;gt; $\log n$ but correlation $\epsilon$ &amp;gt;&amp;gt; $1&#x2F;n$&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;$Cor_U(Maj,d) \leq O(d&#x2F;\sqrt{n})$.&lt;&#x2F;li&gt;
&lt;li&gt;$Cor(Maj,d) \geq O(d^2&#x2F;n)$&lt;&#x2F;li&gt;
&lt;li&gt;$Cor(Maj,1) \leq O(1&#x2F;n)$.&lt;&#x2F;li&gt;
&lt;li&gt;Tight bounds on Cor(Maj,d) are not known (in cases $d\neq 1$).&lt;&#x2F;li&gt;
&lt;li&gt;mod_3 is a candidate for small correlation.&lt;&#x2F;li&gt;
&lt;li&gt;$Cor(mod_3,d) \leq O(d&#x2F;\sqrt{n})$.
&lt;ul&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;Consider any set $X$ for which the polynomial computes $mod_3$ correctly.&lt;&#x2F;li&gt;
&lt;li&gt;Use this polynomial of degree $n&#x2F;2+d$ to now represent any boolean function on $X$.&lt;&#x2F;li&gt;
&lt;li&gt;This gives a relation between the number of functions and the number of polynomials.&lt;&#x2F;li&gt;
&lt;li&gt;This gives the tradeoff between $\lvert X\rvert$ and $d$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hardness Amplification:
&lt;ul&gt;
&lt;li&gt;Given an explicit function $f$ that has correlation $\epsilon$ of some class $C$, construct a related function on $C&#x27;$ with $n&#x27;\sim n$ and \epsilon&#x27; &amp;lt;&amp;lt; \epsilon$.&lt;&#x2F;li&gt;
&lt;li&gt;Yao&#x27;s xor lemma: $f&#x27;=f(x_1)+\dots + f(x_n)$.&lt;&#x2F;li&gt;
&lt;li&gt;Open Question: Does Yao&#x27;s xor lemma hold for polynomials of degree $d\geq \log n$, i.e., $Cor(f,n^{1&#x2F;3})\leq 1&#x2F;3$, $Cor(f&#x27;,\log n^2)\leq 1&#x2F;n^2$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma: The correlation of two majority functions with constant degree polynomials  is $\log^{O(1)}&#x2F;n$.
&lt;ul&gt;
&lt;li&gt;This requires low degree polynomials!&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;bound-2-degree-log-n-but-correlation-1-sqrt-n&quot;&gt;Bound 2: degree &amp;lt;&amp;lt; $\log n$ but correlation $&amp;lt;&amp;lt;1&#x2F;\sqrt{n}$&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;The Inner product function $\sum_{i} x_i x_{i+1}$ has correlation $Cor(IP,1) = 2^{-n&#x2F;2}$.&lt;&#x2F;li&gt;
&lt;li&gt;Generalized Inner Product function has just blocks of size $k$.&lt;&#x2F;li&gt;
&lt;li&gt;For every $n,d$, $Cor(GIP_{d+1},d )\leq \exp(-\Omega(n&#x2F;4^d d))$.&lt;&#x2F;li&gt;
&lt;li&gt;$Cor_D(\mod_3,d) \leq \exp(-n&#x2F;c^d)$. Here the distribution is a bit special.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Smaller ACC0 Circuits for Symmetric Functions</title>
        <published>2022-11-29T01:00:00+00:30</published>
        <updated>2022-11-29T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/smaller-acc0/"/>
        <id>https://narfinger.github.io/posts/2022/smaller-acc0/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/smaller-acc0/">&lt;h1 id=&quot;the-strength-of-equality-oracles-in-communiucation&quot;&gt;The Strength of Equality Oracles in communiucation&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.04706&quot;&gt;Chapman, Williams - Smaller ACC0 Circuits for Symmetric Functions&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;knownledge&quot;&gt;Knownledge&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;We study constant depth circuits with Mod_m gates.&lt;&#x2F;li&gt;
&lt;li&gt;We know that constant depth Mod_q require super-polynomial size circuits to represent Mod_m (if $q$ is a prime).&lt;&#x2F;li&gt;
&lt;li&gt;Little is known if $m$ is not a prime power.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;result&quot;&gt;Result&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;There is a modulus $m\leq (1&#x2F;\epsilon)^{2&#x2F;\epsilon}$ such that every symmetric function on $n$ bits can be computed by a depth 3 MOD_m circuit of size exp($O(n^3)$).&lt;&#x2F;li&gt;
&lt;li&gt;Let $m$ be a prime product then any symmetric function can be computed by depth-$d$ size exp($\tilde O(n^{1&#x2F;(r+d-3)})$ where $r$ is the number of primes.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Any Mod_m gate can be simulated by Mod_mn gate with a fan-in increase factor of $n$.&lt;&#x2F;li&gt;
&lt;li&gt;Every AND of $k$ MOD_b gates can be represented by MOD_a \circ MOD_b circuit of $O(b^k)$ gates.&lt;&#x2F;li&gt;
&lt;li&gt;There is an &lt;em&gt;arithmetic circuit&lt;&#x2F;em&gt; of size $n^{O(i^{2&#x2F;d})}$ of depth $d$ computing the $i$th elementary symmetric polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;Lucas Theorem:
&lt;ul&gt;
&lt;li&gt;For all primes $p$ and natural numbers $n$, $\binom{n}{p^i}\mod p$ is the $i$th digit of the $p$-ary representation of $n$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Main Theorem: Every symmetric function $g$ has a depth-three circuit of the form MOD_5\circ MOD_6 \circ MOD_6 of size $O(\exp(n^{1&#x2F;3}\log n))$&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 3.2: Let $T\subseteq [n]$ be any subset. There is a polynomial $P$ on $n$ variables of degree $O(\sqrt{n})$ that vanishes $\mod 6$.
&lt;ul&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;This uses elementary symmetric polynomials and Lucas theorem.&lt;&#x2F;li&gt;
&lt;li&gt;Let $e_{J}$ be the elementary symmetric polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;For all vectors $a$, $e_{p^i}(a_1,\dots,a_n) = \binom{\sum_i a_i}{J}$.&lt;&#x2F;li&gt;
&lt;li&gt;Define the polynomial $p_2(y_1,\dots,y_n) = 1-\prod_{j=0}^{s-1} (1-(b_j-e_{2^j}(y))\mod 2$.&lt;&#x2F;li&gt;
&lt;li&gt;Now $p_2(a)=0\mod 2$ if and only if the binary representation of $\sum_i a_i$ equals $b_j$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, I can enforce an arbitrary subset size.&lt;&#x2F;li&gt;
&lt;li&gt;A similar thing exists for $\mod 3$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Proof of main theorem:
&lt;ul&gt;
&lt;li&gt;The output gate:
&lt;ul&gt;
&lt;li&gt;Sum over all possible choices of $T\in [n]$ such that $g(T)=1$.&lt;&#x2F;li&gt;
&lt;li&gt;Sum over all possible to partition $T$ into sum of $t=n^{1&#x2F;3}$ parts, called $T_1,\dots,T_t\in [T]$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;We associate each $T_i$ with a set $S_i$ of at most $n^{2&#x2F;3}$ variables.&lt;&#x2F;li&gt;
&lt;li&gt;We can use mod5sum to sum over the choices for $S_i$&lt;&#x2F;li&gt;
&lt;li&gt;We now use a EMAJ polynomial (from Theorem 3.2) to check the sets $S_i$ which is a AND \circ MOD_p for different p.&lt;&#x2F;li&gt;
&lt;li&gt;With the proposition we can change this to a single MOD_6 gate.&lt;&#x2F;li&gt;
&lt;li&gt;We replace AND by MOD_5.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>The strength of equality oracles in communication</title>
        <published>2022-11-21T01:00:00+00:30</published>
        <updated>2022-11-21T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/strength-of-equality-oracles/"/>
        <id>https://narfinger.github.io/posts/2022/strength-of-equality-oracles/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/strength-of-equality-oracles/">&lt;h1 id=&quot;the-strength-of-equality-oracles-in-communiucation&quot;&gt;The Strength of Equality Oracles in communiucation&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2022&#x2F;152&#x2F;&quot;&gt;Pitassi, Shirley, Shraibman - The Strength of Equality Oracles in Communication&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;It is known that equality in communication complexity is the &quot;hardest&quot; function, i.e., needing $\Omega(n)$ bits of communication.&lt;&#x2F;li&gt;
&lt;li&gt;However, for randomized communication, we need only $O(1)$ many bits.&lt;&#x2F;li&gt;
&lt;li&gt;This gives rise to the question: &lt;em&gt;What total function can be efficiently computed in a communication model with oracle access to Equality?&lt;&#x2F;em&gt;
&lt;ul&gt;
&lt;li&gt;Notice that only function with asymptotic less than $O(n)$ are interesting.&lt;&#x2F;li&gt;
&lt;li&gt;In some sense, we allow algorithms to use randomness but only in the restricted sense that we can solve equality.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Some functions can be solved with equality such as greater-than.&lt;&#x2F;li&gt;
&lt;li&gt;But equality cannot simulate all randomized protocols &lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2018&#x2F;206&#x2F;&quot;&gt;Chattopadhyay, Lovett, Vinyals - Equality alone does not simulate randomness&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Hence, Equality is not just all of randomized communication complexity in a complexity class sense.&lt;&#x2F;li&gt;
&lt;li&gt;Questions:
&lt;ul&gt;
&lt;li&gt;What models can be computed if we give stronger communication model (than randomized) as the base with equality oracle access.&lt;&#x2F;li&gt;
&lt;li&gt;What happens if we restrict the reductions in (CLV) to be many-one reductions?&lt;&#x2F;li&gt;
&lt;li&gt;Non-deterministic communication for which no linear bounds are known.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;definitions&quot;&gt;Definitions&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;A blocky matrix is essentially a blowup of an identity matrix with some rows and columns deleted, duplicated or permuted or with zero rows added.&lt;&#x2F;li&gt;
&lt;li&gt;Blocky number is the minimum number of blocky matrices needed to cover a matrix.&lt;&#x2F;li&gt;
&lt;li&gt;Similar with blocky partition number.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;We will omit the cc to denote communication complexity, as we will only talk about communication complexity in this.&lt;&#x2F;strong&gt;&lt;&#x2F;li&gt;
&lt;li&gt;UP is the unambigious nondeterministic model where a prover sends player a witness string after which the players proceed deterministically.&lt;&#x2F;li&gt;
&lt;li&gt;NP^EQ are $2^m$ many P^EQ protocols and the result is the OR of all these executions with EQ oracle access.&lt;&#x2F;li&gt;
&lt;li&gt;$\gamma_2(A) = \min_{X,Y XY^T =A} r(X)r(Y)$ where $r$ is the maximum $l_2$ norm of any row.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;UP^Eq $\leq \log \chi_1(A) \leq O($UP^Eq$ \log n)$ where $\chi_1$ is the minimal $r$ such that $A$ can be expressed as the sum of blocky matrices.&lt;&#x2F;li&gt;
&lt;li&gt;NP^Eq $\leq \log C_1(A) \leq O($NP^Eq$ \log n)$ where $C_1$ is the minium number of blocky matrices such that $A$ is the entry wise OR of these matrices.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>List Colouring Trees in Logarithmic Space</title>
        <published>2022-10-05T01:00:00+00:30</published>
        <updated>2022-10-05T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/coloring-trees/"/>
        <id>https://narfinger.github.io/posts/2022/coloring-trees/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/coloring-trees/">&lt;h1 id=&quot;the-compositon-complexity-of-majority&quot;&gt;The Compositon complexity of majority&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2206.09750v1&quot;&gt;BGJ - List Colouring Trees in Logarithmic Space&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;result&quot;&gt;Result&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;List colouring can be solved on $n$ vertex trees by a deterministic machine using $O(\log n)$ work tape.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Given a graph and a list of possible colors $L(v)$ for all $v$, is there a coloring such that $c(v)\in L(v)$ for all $v$ with $c(v_1)\neq c(v_2)$ if $(u,v)\in T$.&lt;&#x2F;li&gt;
&lt;li&gt;List colouring is hard on planar bipartite graphs even if all lists are of size at most 3.&lt;&#x2F;li&gt;
&lt;li&gt;$W[1]$ hard if parameterized by treewidth.&lt;&#x2F;li&gt;
&lt;li&gt;Can be solved with linear space and linear time on trees with hashing.&lt;&#x2F;li&gt;
&lt;li&gt;The description of the tree and the colors are on a read only tape which does not count for the space complexity.&lt;&#x2F;li&gt;
&lt;li&gt;As trees have pathwidth $O(\log n)$, the problem can be solved non-deterministically in $O(\log^2 n)$ space.&lt;&#x2F;li&gt;
&lt;li&gt;$T_v$ is the subtree rooted at $v$ and $T-v$ the forest resulting from deleting $v$.&lt;&#x2F;li&gt;
&lt;li&gt;Traversing a tree can be done in $O(\log n)$ space. Same with count the number of vertices in a subtree, child with the maximum subtree size, enumerate children ordered by the subtree size.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;path-decompositions&quot;&gt;Path Decompositions.&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;A path decomposition is a tree decomposition that is a path.&lt;&#x2F;li&gt;
&lt;li&gt;A nice path decomposition has empty bags on the endpoints of the path, and two consecutive bags differ only by at most one vertex.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;warmup&quot;&gt;Warmup&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;List colouring can be solved non-deterministically using $O(\log n\log \Delta)$ space of trees with maximum degree $\Delta$.
&lt;ul&gt;
&lt;li&gt;This uses the following two lemmas&lt;&#x2F;li&gt;
&lt;li&gt;List colouring can be solved non-deterministically in $O(k\log \Delta + \log n)$ space if we can compute deterministically a path decomposition for $G$ with width $k$ in $O(\log n)$ space.&lt;&#x2F;li&gt;
&lt;li&gt;If $T$ is a tree, we can deterministically compute a path decomposition of width $O(\log n)$ using $O(\log n)$ space.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;We call a vertex heavy if its subtree has &lt;em&gt;more&lt;&#x2F;em&gt; vertices than any other of its siblings from the same parent.&lt;&#x2F;li&gt;
&lt;li&gt;Now a way to do this would be Loop over possible colours of the root $v$ and then check if a colouring can be extended to all subtrees $T_v$ for $v$ being a child of the root while not giving the colour $c$ to the root.
&lt;ul&gt;
&lt;li&gt;Having for this a space bound of $S(n) = f(n)\log n$ gives us a recursive space of $S(n&#x2F;2) \leq S(n)-f(n)$.&lt;&#x2F;li&gt;
&lt;li&gt;So when we recursive on a non-heavy child we are fine with some bits to spare.
&lt;ul&gt;
&lt;li&gt;Suppose now $v$ has non-heavy children $v_1,\dots,v_k$ and heavy child $u$.&lt;&#x2F;li&gt;
&lt;li&gt;Suppose the parent of $v$ needs to be assigned colour $c&#x27;$. Then one of the following must be true:
&lt;ul&gt;
&lt;li&gt;There is no colouring of $T_v-T_u$ which avoids colour $c&#x27;$ for $v$. This implies reject as it contradicts the edge of $parent(v)$ and $v$&lt;&#x2F;li&gt;
&lt;li&gt;There is a unique colour $c\neq c&#x27;$ that can be assigned to $v$ for a list colouring of $T_v-T_u$.&lt;&#x2F;li&gt;
&lt;li&gt;There are two possible colours unequal to $c&#x27;$ which can be given to $T_v-T_u$ and it can be coloured for the heavy child $T_v$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;A deterministic algorithm using $O(\log^2 n)$ space and poly time.
&lt;ul&gt;
&lt;li&gt;Algorithm Solve(v,p) where $p$ denotes that $v$ cannot recieve the $p$th colour in $L(v)$ (0 mean no restriction):
&lt;ul&gt;
&lt;li&gt;Let the children of $v$ be $v_1,\dots,v_k$ and $u$ the heavy child.&lt;&#x2F;li&gt;
&lt;li&gt;Recursively verify that $v_i$ can be coloured by using Solve($v_i$,0). Reject if any rejects.&lt;&#x2F;li&gt;
&lt;li&gt;If $|L(v)| \geq k+2$ we free up our memory and verify that $T_u$ can be coloured by calling Solve($u$,0).&lt;&#x2F;li&gt;
&lt;li&gt;Assume now $\lvert L(v)\rvert\leq k+1$. Check if there is some colour $p$ that we can colour and recursively ask if this is possible by using Solve($v_i$,$p$). This excludes the heavy child obviously. Reject if no such colour exists.&lt;&#x2F;li&gt;
&lt;li&gt;Check if there is at least a second way to colour $T\setminus T_u$ and call this $p_2$.&lt;&#x2F;li&gt;
&lt;li&gt;If yes, free up memory and recursively verify that $T_u$ can be coloured with Solve($u$,0).
&lt;ul&gt;
&lt;li&gt;Notice that we do not have to try $p_1$.&lt;&#x2F;li&gt;
&lt;li&gt;This is because it is a tree and $u$ can take any colour it wants.&lt;&#x2F;li&gt;
&lt;li&gt;If $u$ has colour $p_1$ we set $r$ to $p_2$ and $p_1$ otherwise.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;If not then we colour $r$ with $p_1$ and recursively verify with Solve($u$,$p&#x27;$) where $p&#x27;$ is the apropiate colour in $u$s list if it exists.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;final-proof&quot;&gt;Final Proof&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Two main ideas:
&lt;ul&gt;
&lt;li&gt;Storing the colour can be done by storing the index of the list and it can be recomputed.&lt;&#x2F;li&gt;
&lt;li&gt;The space used for the colour will depend on the size of the sub-tree. A bracketing idea makes this easier. So the remaining is small.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Data Structure Lower Bounds Short Survey</title>
        <published>2022-06-13T01:00:00+00:30</published>
        <updated>2022-06-13T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/2022-06-13-datastructure-survey/overview/"/>
        <id>https://narfinger.github.io/posts/2022/2022-06-13-datastructure-survey/overview/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/2022-06-13-datastructure-survey/overview/">&lt;p&gt;I wrote a survey on some recent results in data structure lower bounds. It can be found &lt;a href=&quot;https:&#x2F;&#x2F;narfinger.github.io&#x2F;posts&#x2F;2022&#x2F;2022-06-13-datastructure-survey&#x2F;overview&#x2F;here&quot;&gt;main.pdf&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Sorting Balls and Water: Equivalence and Computational Complexity</title>
        <published>2022-06-02T01:00:00+00:30</published>
        <updated>2022-06-02T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/sorting-balls/"/>
        <id>https://narfinger.github.io/posts/2022/sorting-balls/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/sorting-balls/">&lt;h1 id=&quot;paper&quot;&gt;Paper&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2202.09495&quot;&gt;Takehiro Ito, Jun Kawahara, Shin-ichi Minato, Yota Otachi, Toshiki Saitoh, Akira Suzuki, Ryuhei Uehara, Takeaki Uno, Katsuhisa Yamanaka, Ryo Yoshinaka - Sorting Balls and Water&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Bins colored with some units (balls or water) and the goal is to sort them.&lt;&#x2F;li&gt;
&lt;li&gt;Each bin works as a stack.&lt;&#x2F;li&gt;
&lt;li&gt;$hn$ balls, $n$ bins of capacity $h$ and $k$ empty bins.&lt;&#x2F;li&gt;
&lt;li&gt;Balls need to be sorted in a move onto empty bins or balls of the same color.&lt;&#x2F;li&gt;
&lt;li&gt;Water is very similar.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Water and Ball are actually equivalent.&lt;&#x2F;li&gt;
&lt;li&gt;They are NP-complete.&lt;&#x2F;li&gt;
&lt;li&gt;Are solvable in $h^n$ time.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;some-proof-notes&quot;&gt;Some Proof notes&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Reduction from 3 Partition.&lt;&#x2F;li&gt;
&lt;li&gt;3 Partition:
&lt;ul&gt;
&lt;li&gt;Given $a_1,\dots, a_{3m}$ with $\sum_{i} a_i = mB$.&lt;&#x2F;li&gt;
&lt;li&gt;$B&#x2F;4 &amp;lt; a_i B&#x2F;2$.&lt;&#x2F;li&gt;
&lt;li&gt;Is there a partition into subsets $A_1,\dots, A_m$ such that $\sum_{i\in A_j} a_i = B$?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;First direction: 3part -&amp;gt; water
&lt;ul&gt;
&lt;li&gt;We construct the following coloring from a 3 partition set:&lt;&#x2F;li&gt;
&lt;li&gt;Top contains only red and rest is blue.&lt;&#x2F;li&gt;
&lt;li&gt;From here we have an empty container and can fill it with the first set. Then compact and continue with the next set.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Other direction by membership.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>On Reconfiguration Graph of Independent Sets under Token Sliding</title>
        <published>2022-06-01T01:00:00+00:30</published>
        <updated>2022-06-01T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/token-sliding/"/>
        <id>https://narfinger.github.io/posts/2022/token-sliding/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/token-sliding/">&lt;h1 id=&quot;paper&quot;&gt;Paper&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2203.16861&quot;&gt;Avis, Hoang - On Reconfiguration Graph of Independent Sets under Token Sliding&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Put a token on one vertex of every independent set of a given graph $G$.&lt;&#x2F;li&gt;
&lt;li&gt;Tokens can slide to neighbours that are not occupied.&lt;&#x2F;li&gt;
&lt;li&gt;Construct a new graph $G&#x27;$ in the following way: Two vertices are adjacent if we can slide one token to one of its adjacent vertices.&lt;&#x2F;li&gt;
&lt;li&gt;This is called TS or TS$_k$ if we restrict ourselves to independent sets of size $k$.&lt;&#x2F;li&gt;
&lt;li&gt;Questions:
&lt;ul&gt;
&lt;li&gt;Does TS$_k(G)$ belong to some graph class?&lt;&#x2F;li&gt;
&lt;li&gt;If $G$ satisfies some property, does $TS(G)$ also satisfy the property and vice versa?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;TS_k($\bar G$) is a subgraph of the graph whose nodes are size $k$ cliques and two nodes are adjacent if they have exactly $k-1$ vertices in common.&lt;&#x2F;li&gt;
&lt;li&gt;If $H$ is an induced subgraph of $G$ then TS$_k(H)$ is an induced subgraph of TS$_k(G)$ (but not the reverse).&lt;&#x2F;li&gt;
&lt;li&gt;TS$(P_n)$ is planar for every $n\leq 8$ but non-planar otherwise (where $P_n$ is a planar graph on $n$ vertices),&lt;&#x2F;li&gt;
&lt;li&gt;More similar results.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>The Composition Complexity of Majority</title>
        <published>2022-05-11T01:00:00+00:30</published>
        <updated>2022-05-11T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/the-composition-complexity-of-majority/"/>
        <id>https://narfinger.github.io/posts/2022/the-composition-complexity-of-majority/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/the-composition-complexity-of-majority/">&lt;h1 id=&quot;the-compositon-complexity-of-majority&quot;&gt;The Compositon complexity of majority&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2205.02374&quot;&gt;LRT - The Composition Complexity of Majority&lt;&#x2F;a&gt;
&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=C3_VCwPAh_0&quot;&gt;Talk&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;result&quot;&gt;Result&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Can majority be given as $h(g_1,\dots,g_m)$ with $g_m$ a function that queries only $k&amp;lt;&amp;lt;n$ many bits and $h$ an arbitrary function.&lt;&#x2F;li&gt;
&lt;li&gt;They prove an optimal $m\geq \Omega(n&#x2F;k \log k)$ lower bound.&lt;&#x2F;li&gt;
&lt;li&gt;The upper bound is easy to see.
&lt;ul&gt;
&lt;li&gt;Split the variables into $n&#x2F;k$ disjoint set.&lt;&#x2F;li&gt;
&lt;li&gt;Use $\log k$ of the functions per block to output the hamming weight.&lt;&#x2F;li&gt;
&lt;li&gt;Use $h$ to compute the overall hamming weight and compute majority from this.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Also: This implies lower bounds for bounded with branching programs.&lt;&#x2F;li&gt;
&lt;li&gt;Also: Lower bounds for small depth circuits.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Key Insight:
&lt;ul&gt;
&lt;li&gt;Suppose $x_i$ is queried by at most $q$ of the inner functions. Then $I[X_i \mid g_1(X),\dots, g_m(X)]\geq 2^{-O(q)}$.&lt;&#x2F;li&gt;
&lt;li&gt;I.e., the information of $X_i$ under knowing $g_1,\dots,g_m$ is greater than the information from $q$ equally distributed bits.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;They will prove show a lower bound for the hamming function $H:{0,1}^n \rightarrow {0,1}^{\log n}$ (Section 4),&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;preliminaries&quot;&gt;Preliminaries&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;$x^{(i-&amp;gt;b)} = (x_1,\dots,x_{i-1},b,x_{i+1},\dots,x_n)$.&lt;&#x2F;li&gt;
&lt;li&gt;$x^{\oplus i} = (x_1,\dots,x_{i-1},1\oplus x_i,x_{i+1},\dots,x_n)$.&lt;&#x2F;li&gt;
&lt;li&gt;We call a function $k$-local if there exists a set $\lvert I\rvert=k$ such that $f(x)=f(x^{\oplus j})$ for all $x$, for all  $j\in [n]\setminus I$, i.e., it depends only on variables in $I$.&lt;&#x2F;li&gt;
&lt;li&gt;$k$-composition complexity of a function is is the minimum integer such that there exists functions $g_1,\dots,g_m:{0,1}^n\rightarrow {0,1}$ and $h:{0,1}^m \rightarrow D$ with the properties that $h(g_1,\dots,g_m)=f$ and every $g_j$ is $k$-local. We denote this by $C_k(f)$.&lt;&#x2F;li&gt;
&lt;li&gt;A function is self-containing if for any there is a sub function of $f_n$ on $I$ that computes $F_{\lvert I\rvert}$.
&lt;ul&gt;
&lt;li&gt;Majority and Hamming are self-containing.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;If a function is self-containing and $C_k(f_n)\leq m$ then we can write it such that each $g_j$ is $k$-local and each variables is queried at most $mk&#x2F;n$ times.
&lt;ul&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;Let $q=mk&#x2F;2n$.&lt;&#x2F;li&gt;
&lt;li&gt;On average each variable is queried at most $q$ times.&lt;&#x2F;li&gt;
&lt;li&gt;By Markov Inequality at most half of the variables are queried more than $2q$ times.&lt;&#x2F;li&gt;
&lt;li&gt;The probability distribution is over choice of variables.&lt;&#x2F;li&gt;
&lt;li&gt;Now put the variables that are queried at most $2q$ times into a set $I$.&lt;&#x2F;li&gt;
&lt;li&gt;As our function is self-containing this now computes $f_{n&#x2F;2}$.&lt;&#x2F;li&gt;
&lt;li&gt;This finishes the proof.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;We need $g_j$ to be $k$-local as otherwise the function could use more than $k$ bits.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Now this can be used to prove a bound on $C_k(f)$ in the obvious contraposition.&lt;&#x2F;li&gt;
&lt;li&gt;We denote by $H$ the entropy.&lt;&#x2F;li&gt;
&lt;li&gt;Mutal information: $I[X\mid Y] = H[X]-H[X\mid Y]$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-of-key-insight-lemma&quot;&gt;Proof of Key Insight Lemma&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Statement:
&lt;ul&gt;
&lt;li&gt;Let $f$ be the Hamming weight function and a variable $i$ be queried by at most $q$ inner functions. Then $H(X_i \mid g_1(X),\dots, g_m(X)) \leq 1+ \Pr[X^{\oplus 1}\not\in D] - 2^{-O(q)}$ where $D$ is the domain of the function $f$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;proof-for-q-1&quot;&gt;Proof for $q=1$&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Proposition 5.1
&lt;ul&gt;
&lt;li&gt;$H[X_i] - H[X_i \mid g_1(X),\dots,g_m(X)]=1$.&lt;&#x2F;li&gt;
&lt;li&gt;I.e., the output of the inner functions determine $X_i$ completely.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;Assume wlog that the only function querying $X_i$ is $g_1$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we want to recover $x_i$ from $g_1,\dots,g_m$.&lt;&#x2F;li&gt;
&lt;li&gt;By our assumption $\lvert x\rvert=h(g_1,\dots,g_m)$.&lt;&#x2F;li&gt;
&lt;li&gt;So $\lvert x\rvert$ is given either by $h(0,g_2,\dots,g_m)$ or $h(1,g_2,\dots,g_m)$.&lt;&#x2F;li&gt;
&lt;li&gt;Now look at $x^{\oplus i}$. This does not change $g_2,\dots,g_m$ because we choose $q=1$.&lt;&#x2F;li&gt;
&lt;li&gt;As this changes the hamming weight of the output, it means that $g_1$ flips when $x_i$ flips.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, as everything else is fixed (because the $g_i$ are local), this is the only bit of information.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that we have the computation of $g_1,\dots,g_m$ given.&lt;&#x2F;li&gt;
&lt;li&gt;Now compare $h(g_1,\dots,g_m)$ vs the hamming weight of $x^{i-&amp;gt;0}$ and $x^{i-&amp;gt;1}$.&lt;&#x2F;li&gt;
&lt;li&gt;One of them will fit with the computed hamming weight of $h$ and, hence, be the correct one.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we completely recovered $X_i$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;General Case:
&lt;ul&gt;
&lt;li&gt;Let $J_i$ be the set of inner functions that depend on variable $i$.&lt;&#x2F;li&gt;
&lt;li&gt;Now $H[X_i \mid g_1(X),\dots,g_m(X)]\leq H[X_i \mid { g_j(X) \mid j\in \bar J_i}, \lvert X\rvert]$, i.e., the all the functions that don&#x27;t depend on $i$.
&lt;ul&gt;
&lt;li&gt;This is ok because $g_1,\dots,g_m$ determine $\lvert X\rvert$ completely.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, this is potentially only more information but not less we are given.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This is now by definition $E_{Y\sim D}[-\log \Pr[X_i=Y_i\mid (\forall j\in \bar J_i, g_j(X)=g_j(Y)) \land \lvert X\rvert = \lvert Y\rvert)]]$.&lt;&#x2F;li&gt;
&lt;li&gt;This is equal to $E_{Y\sim D}[H_2(\Pr[X_i=Y_i\mid (\forall j\in \bar J_i, g_j(X)=g_j(Y)) \land \lvert X\rvert = \lvert Y\rvert)])]$ where this is the binary entropy function, i.e., $-p\log p - (1-p)\log (1-p)$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we need to bound this by $1+\Pr[X^{\oplus i}\not \in D] -2^{-O(q)}$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we prove this inequality.
&lt;ul&gt;
&lt;li&gt;Fix output values by $v\in {0,1}^{\bar J_i}$ of the inner functions that do not query variable $i$.&lt;&#x2F;li&gt;
&lt;li&gt;Suppose these output values are achievable by some input $x\in D$.&lt;&#x2F;li&gt;
&lt;li&gt;Define $S_v = { x \mid \forall j\in \bar J_i, g_j(x)=v_j }$ the set of inputs that produce the values for the inner functions.&lt;&#x2F;li&gt;
&lt;li&gt;This $S_v$ partitions the distribution $D$.&lt;&#x2F;li&gt;
&lt;li&gt;We call a $v$ good if $\Pr[X^{\plus i}\not\in D \mid X\in S_v]\leq 2\Pr[X^{\oplus i}\not\in D]$.&lt;&#x2F;li&gt;
&lt;li&gt;By Markov, the sets $S_v$ with good $v$ account for at most probablity mass, i.e., $\sum_{v \text{is good}} \Pr[X\in S_v] \geq 1&#x2F;2$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we show that our required equation holds for every good $v$.&lt;&#x2F;li&gt;
&lt;li&gt;Let $W_v$ be the set of possible hamming weights with $x\in D\cap S_v$.&lt;&#x2F;li&gt;
&lt;li&gt;It can only depend on the remaining $q$ input values $g_j(x)$ for $j\in J_i$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we want to have that there exists a Hamming Weight that occurs with significant probability within $S_v$ such that conditioned on this we can guess $X_i=1$ with better than random chance.&lt;&#x2F;li&gt;
&lt;li&gt;To prove (1): $\Pr[\lvert X\rvert =w^* \mid x\in S_v]\geq 2^{-O(q)}$&lt;&#x2F;li&gt;
&lt;li&gt;To Prove (2): $\Pr[X_i=1 \mid X\in S_v\cap \lvert X\rvert=w^*]\leq 1&#x2F;2 - 2^{O(q)}$.&lt;&#x2F;li&gt;
&lt;li&gt;This implies our equation by simple calculations which we skip.&lt;&#x2F;li&gt;
&lt;li&gt;To find this $w^*$ we know:
&lt;ul&gt;
&lt;li&gt;If $x\in S_v$ then $x^{\oplus i}\in S_v$. This gives us a naive pairing of values in $S_v$.&lt;&#x2F;li&gt;
&lt;li&gt;Now define $p_w = \Pr[X^{\oplus i}\in D, \lvert X^{i-&amp;gt; 0}\rvert = w \mid X\in S_v]$.&lt;&#x2F;li&gt;
&lt;li&gt;This has at most $2\lvert W_v\rvert$ non-zero elements.&lt;&#x2F;li&gt;
&lt;li&gt;The total sum is at least $1-2^{-10q+1}$&lt;&#x2F;li&gt;
&lt;li&gt;The maximum is at least $2^{-q-2}$.&lt;&#x2F;li&gt;
&lt;li&gt;So there exists a weight $w*$ such that $p_{w^&lt;em&gt;} \geq p_{w^&lt;&#x2F;em&gt;-1} + 2^{-2q-3}$.&lt;&#x2F;li&gt;
&lt;li&gt;This $w^*$ turns out to satisfy the equations.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Notice that the Lemma does not automatically say anything about if this is possible or not.
&lt;ul&gt;
&lt;li&gt;This only gives a contradiction if this lemma gives us more information via $I[X_i \mid g_1,\dots,g_m]$ then $I[g_1(X),\dots,g_m(X)]$.&lt;&#x2F;li&gt;
&lt;li&gt;For majority, the Lemma gives $\Omega(n)$ information but $n&amp;gt;&amp;gt;m$ which is the information of the $g_i$.&lt;&#x2F;li&gt;
&lt;li&gt;Looking at Parity, the&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;observations&quot;&gt;Observations&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Notice that the lemma does not work for Parity and similar things.
&lt;ul&gt;
&lt;li&gt;The reason can be seen in the $q=1$ case.&lt;&#x2F;li&gt;
&lt;li&gt;Here given $g_1,\dots,g_m$ we can still get $x_i \oplus 0$ and $x_i \oplus 1$.&lt;&#x2F;li&gt;
&lt;li&gt;In the Hamming Weight case I can check if the Hamming weight goes up or down with the bit flip.&lt;&#x2F;li&gt;
&lt;li&gt;With Parity it will always flip.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;questions&quot;&gt;Questions&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Can we improve this to not just be on hamming weight function, i.e., functions that are a bit different then what they say?&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;UNCHECKED&lt;&#x2F;strong&gt; Can we improve this to other functions?&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;UNCHECKED&lt;&#x2F;strong&gt; Does this work for monotone symmetric functions?
&lt;ul&gt;
&lt;li&gt;One thing I am not sure is if I can always reconstruct it.&lt;&#x2F;li&gt;
&lt;li&gt;Can it happen that we do not get any response&#x2F;difference?&lt;&#x2F;li&gt;
&lt;li&gt;In the simple case not but the other case is more difficult.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>An Optimal Algorithm for Certifying Monotone Functions</title>
        <published>2022-05-03T01:00:00+00:30</published>
        <updated>2022-05-03T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2022/certifying-local/"/>
        <id>https://narfinger.github.io/posts/2022/certifying-local/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2022/certifying-local/">&lt;h1 id=&quot;2022-04-04-gupta-manoj-an-optimal-algorithm-for-certifying-monotone-functions&quot;&gt;2022-04-04 Gupta, Manoj - An Optimal Algorithm for Certifying Monotone Functions&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2022&#x2F;044&#x2F;&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;result&quot;&gt;Result&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Query Access to Monotone function of some certifying complexity ($C(f)$)and input $x^*$&lt;&#x2F;li&gt;
&lt;li&gt;Output a $C(f)$ sized subset of $x^* $ certifying the value of $f(x^*)$.
&lt;ul&gt;
&lt;li&gt;Makes $O(C(f)\log n)$ queries which matches the information theoretic lower bound.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Extended to real valued function.&lt;&#x2F;li&gt;
&lt;li&gt;Show lower bound of $\Omega(\binom{n}{C(f)})$ queries in the worst case for finding the shortest certificate.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;A certificate is the value of bits that &quot;fix&quot; $f(x)$.&lt;&#x2F;li&gt;
&lt;li&gt;Let $x$ (otherwise denoted by $x^* $) be an input $S\subseteq [n]$ is a certificate if for all $y$ such that $x|_S=y|_S$ implies $f(x)=f(y)$.&lt;&#x2F;li&gt;
&lt;li&gt;The certificate size is the $\max_{x\in {0,1}^n} \min_j$ exists a certificate for $f$ of size $j$.&lt;&#x2F;li&gt;
&lt;li&gt;There exists a randomized algorithm that for monotone boolean functions, with at most $O(C(f)^8 \log n)$ queries that outputs at such a certificate for a given input.&lt;&#x2F;li&gt;
&lt;li&gt;$O(C(f)\log n)$ queries are necessary.&lt;&#x2F;li&gt;
&lt;li&gt;For non-monotone functions $\Omega(2^{C(f)} + C(f)\log n)$ queries are necessary.&lt;&#x2F;li&gt;
&lt;li&gt;And $O(2^{C(f)} \cdot C(f)\log n)$ queries are sufficient for a randomized algorithm.&lt;&#x2F;li&gt;
&lt;li&gt;Definition:
&lt;ul&gt;
&lt;li&gt;$x_S$ is the indicator vector and $x|_S$ the coordinates.&lt;&#x2F;li&gt;
&lt;li&gt;$S_x$ is the set coming from the vector $x\in {0,1}$.&lt;&#x2F;li&gt;
&lt;li&gt;Minimal Certificate:
&lt;ul&gt;
&lt;li&gt;A certificate is minimal if for all $S\setminus a$ is not a certificate for $a\in S$.&lt;&#x2F;li&gt;
&lt;li&gt;For monotone this is equivalent to: for all $A\subset S$ $f(x|_A)\neq f(x|_S)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;algorithm&quot;&gt;Algorithm&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Algorith:
&lt;ul&gt;
&lt;li&gt;Input: Query Access to $f$, $x$ with $f(x)=1$.&lt;&#x2F;li&gt;
&lt;li&gt;Set $A=\emptyset$, $S=S_x$, i.e., all indices where $x_i=1$.&lt;&#x2F;li&gt;
&lt;li&gt;Run until $f(x_A)=1$
&lt;ul&gt;
&lt;li&gt;Set $s\leftarrow \text{search}(f,A,S)$.&lt;&#x2F;li&gt;
&lt;li&gt;Add $s$ to $A$.&lt;&#x2F;li&gt;
&lt;li&gt;Set $S = S\cap [s-1]$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Output $A$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Search:
&lt;ul&gt;
&lt;li&gt;On Input $f,A,S$ output the smallest $s\in S$ such that $f(x_{A\cup ([s]\cap S)})=1$ with binary search.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Proof of Correctness:
&lt;ul&gt;
&lt;li&gt;$f(A)=1$ by the loop condition.&lt;&#x2F;li&gt;
&lt;li&gt;Assume any $A\setminus s$ with $s\in A$.
&lt;ul&gt;
&lt;li&gt;Then $f(A\setminus s)=0$.&lt;&#x2F;li&gt;
&lt;li&gt;It must be the case that $f(x_{S\cap [s-1]\cup A})=0$ but $f(x_{S\cap [s]\cup A})=1$. Otherwise $s$ would not have been picked by the binary search algorithm&lt;&#x2F;li&gt;
&lt;li&gt;All future elements that are added to the certificate must be in $S\cap [s-1]$ if $A$ is not allready minimal.&lt;&#x2F;li&gt;
&lt;li&gt;But $f(x_{S\cap [s-1]\cup A})=0$, a contradiction.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Proof of Runtime:
&lt;ul&gt;
&lt;li&gt;$A$ has at most $C(f)$ coordinates.&lt;&#x2F;li&gt;
&lt;li&gt;Every step we add another element to $A$.&lt;&#x2F;li&gt;
&lt;li&gt;The binary search uses $\log n$ steps.&lt;&#x2F;li&gt;
&lt;li&gt;Checking if $f(x_A)=1$ uses one query.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $C(f)(\log n +1)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;blanc-koch-lange-tan-the-query-complexity-of-certification&quot;&gt;Blanc, Koch, Lange, Tan - The Query Complexity of Certification&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Claim 1.1: Any query algorithm that starts with $x$ and goes through hamming neighbours iteratively needs $\Omega(\epsilon n)$ time.
&lt;ul&gt;
&lt;li&gt;Notice that the above algorithm is not doing this.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Claim 1.2: Lower bound of $\Omega(k\log n)$ where $k$ is the certificate size for monotone functions.&lt;&#x2F;li&gt;
&lt;li&gt;Claim 8.3: $\Omega(2^k + k\log n)$ for arbitrary functions.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proofs&quot;&gt;Proofs&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Yao&#x27;s Lemma:
&lt;ul&gt;
&lt;li&gt;Let $R_q$, $D_q$ be the set of all $q$-query randomized and deterministic algorithms respectively.&lt;&#x2F;li&gt;
&lt;li&gt;Let $I$ be the set of all possible pairs $f:{0,1}^n \rightarrow {0,1}$ and $x$ an instance.&lt;&#x2F;li&gt;
&lt;li&gt;For any distribution $\mu$ on $I$ $\min_{R\in R_q} \max_{(f,x)\in I} [\text{error}&lt;em&gt;R(f,x)] \geq \min&lt;&#x2F;em&gt;{D\in D_q} E_{f,x\sim \mu}[\text{error}_D(f,x)]$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Claim 7.6:
&lt;ul&gt;
&lt;li&gt;There is some monotone function with $C(f)\leq k$ and input $x$ on which a $q$-query algorithm $A$ successfully returns and a size $l$ certificate for $x$ with probability $2^q \binom{l}{k}&#x2F;\binom{n}{k} \leq 2^q (ne&#x2F;n)^k$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;own-thoughts&quot;&gt;Own Thoughts&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Notice that communication complexity is difficult to apply as our outut is a set of numbers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Small Circuits Imply Efficient Arthur-Merlin Protocols</title>
        <published>2021-11-25T01:00:00+00:30</published>
        <updated>2021-11-25T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/small-circuit-arthur-merlin/"/>
        <id>https://narfinger.github.io/posts/2021/small-circuit-arthur-merlin/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/small-circuit-arthur-merlin/">&lt;h1 id=&quot;2021-08-30-dm-small-circuits-imply-efficient-arthur-merlin-protocols&quot;&gt;2021-08-30-DM-Small Circuits Imply Efficient Arthur-Merlin Protocols&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2021&#x2F;127&#x2F;&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;result&quot;&gt;Result&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;small-boolean-circuits&quot;&gt;Small Boolean Circuits&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;$&amp;lt;x,y&amp;gt; = \sum_i x_i y_i \mod 2$ is the inner product function.&lt;&#x2F;li&gt;
&lt;li&gt;It can be easily computed by constant depth circuits with $\oplus$ gates (AC$^0_\oplus$).&lt;&#x2F;li&gt;
&lt;li&gt;What if we only allow $\oplus$ gates only at the bottom?&lt;&#x2F;li&gt;
&lt;li&gt;If we do not allow $\oplus$ gates than showing a lower bound is easy.&lt;&#x2F;li&gt;
&lt;li&gt;DNF of parities has also an exponential lower bound.&lt;&#x2F;li&gt;
&lt;li&gt;Depth 3 circuits only have a weak quadratic lower bound.&lt;&#x2F;li&gt;
&lt;li&gt;For arbitrary depth (AC$^0_\oplus$) and the number of parity gates is linear, a lower bound is known.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;communication-complexity&quot;&gt;Communication Complexity&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Arthur-Merlin protocol where there is an all powerful prover and a verifier.&lt;&#x2F;li&gt;
&lt;li&gt;AM Data Streaming Model (AM[$k$])
&lt;ul&gt;
&lt;li&gt;Merlin sees the complete input.&lt;&#x2F;li&gt;
&lt;li&gt;Verifier sees a stream and is space bounded.&lt;&#x2F;li&gt;
&lt;li&gt;Phases:
&lt;ul&gt;
&lt;li&gt;First phase: Verifier engages in a $k$-message public coin protocol with the prover, resulting in a transcript $\tau$.&lt;&#x2F;li&gt;
&lt;li&gt;Second phase: Verifier works deterministically on the input as a stream and is allowed to look at $\tau$.&lt;&#x2F;li&gt;
&lt;li&gt;Third phase: Verifier accepts or rejects.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;There exists a strategy for Merlin that convinces the verifier to accept true statements.&lt;&#x2F;li&gt;
&lt;li&gt;No strategy makes the Verifier accept false statements.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This also can work as a communication complexity protocol with the same bounds.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;result-1&quot;&gt;Result&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;If there exists a DNF of parities of size $s$ that computes the inner product function on $5&#x2F;6+\epsilon$ fraction of the inputs for some constant $\epsilon$. Then there exists a AM[$k$] with $\tilde O(d)\log s$ proof length, space complexity and randomness complexity for every polynomial over $GF(2)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;holographic-ip&quot;&gt;Holographic IP&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Verifier instead of having the input is given an encoding of the input, similar to PCP.&lt;&#x2F;li&gt;
&lt;li&gt;Construct a protocol that works for most inputs.
&lt;ul&gt;
&lt;li&gt;Prover picks sends an index to a satisfied clause. Verifier, verifies that this is correct.
&lt;ul&gt;
&lt;li&gt;The size bound is $\log s$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;However, large width DNF would be a problem.&lt;&#x2F;li&gt;
&lt;li&gt;We can see DNF clauses as a system of linear equations. We now remove wide clauses but make sure that the rank of this system does not decrease.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that if the DNF is not fulfilled then there does not exist a single clause that is true. Hence the prover cannot prove this.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;To make this protocol work for all most inputs we want to use the equation $&amp;lt;x,y&amp;gt; = &amp;lt;x \oplus u,y\oplus v&amp;gt; \oplus &amp;lt;x\oplus u,v&amp;gt; \oplus &amp;lt;u,y\oplus v&amp;gt; \oplus &amp;lt;u,v&amp;gt;$.
&lt;ul&gt;
&lt;li&gt;However, for this would need to verify zero cases too.&lt;&#x2F;li&gt;
&lt;li&gt;A cheating prover cannot lie in the one cases but has to lie in the zero cases.&lt;&#x2F;li&gt;
&lt;li&gt;We expect roughly equal amount of ones and zero cases of our equation.&lt;&#x2F;li&gt;
&lt;li&gt;The Verifier will now ask for a couple of randomly chosen strings $u,v$, check the one claims and accepts the zero claims.&lt;&#x2F;li&gt;
&lt;li&gt;Then it checks that the average value is close enough to the expected value.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Smaller ACC0 Circuits for Symmetric Functions</title>
        <published>2021-11-17T01:00:00+00:30</published>
        <updated>2021-11-17T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/symmetric-mod-bound/"/>
        <id>https://narfinger.github.io/posts/2021/symmetric-mod-bound/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/symmetric-mod-bound/">&lt;h1 id=&quot;2021-07-09-cw-smaller-acc0-circuits-for-symmetric-functions&quot;&gt;2021-07-09-CW-Smaller ACC0 Circuits for Symmetric Functions&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2107.04706v1&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Theorem 1.1: For every $\epsilon$ and $m&amp;lt;(1&#x2F;3)^{2&#x2F;\epsilon}$ such that every symmetric function can be computed by a depth 3 circuit of form $\mod_{p_1}\circ \mod_{p_2,\dots,p_r}\circ \mod_{p_r}$ where these are distinct primes of size $\exp(O(n^{\epsilon}))$.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 1.2: Every symmetric function can be computed by a depth $d$ $\mod_m$ circuit of size $\exp(\tilde O(n^{1&#x2F;(r+d-3)}))$.&lt;&#x2F;li&gt;
&lt;li&gt;Hypothesis (Sym And): There is a function $f$ computable by a TC$_0$ circuit with at most $\tilde O(n)$ gates with fan-in $\tilde O(n)$ such that $f$ does not have $\exp(O(n^{1&#x2F;k}))$ size $\text{SYM}\circ \text{AND}$ circuits.&lt;&#x2F;li&gt;
&lt;li&gt;ACC$_0[m]$ is the class of constant depth poly size circuits with unbounded fan-in that are allowed $\mod_m$ gates.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 1.5: Assuming Sym And Hypothesis there is a fixed $\alpha$ such that for every $m,d$, every ACC$_0[m]$ computing the majority function has size at least $\exp(n^{\alpha&#x2F;rd})$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof-of-theorem-1-1&quot;&gt;Proof of Theorem 1.1&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;prerequisite&quot;&gt;Prerequisite&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Lucas Theorem: $\binom{n}{p^i}\mod p$ is the $i$th digit in the $p$-ary representation of $n$.
&lt;ul&gt;
&lt;li&gt;This implies that taking the elementary symmetric polynomial $e_{p^i}(a_1,\dots,a_n)\mod p$ of degree $p^i$ equals the $i$th digit in the $p$-ary representation of $\sum_i a_i$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Proposition 2.2(BIS90,CP19): Let $a,b$ be fixed integers with $\gcd(a,b)=1$. Every $\land\circ \mod_b$ gate can be represented by a $\mod_a\circ\mod_b$ circuit of $O(b^k)$ gates.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 3.1 (Non Generalized form of 1.1): Every symmetric boolean function has a depth 3 circuit of the form $\mod_5 \circ \mod_6\circ \mod 5$ of size $\exp(O(n^{1&#x2F;3} \log n))$.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 3.2: For every $T\in {0,1,\dots,n}$ there exists a polynomial on $n$ variables of degree at most $3\sqrt{n}$ such that for all $a\in {0,1}^n$, $P_T(a)=0\mod 6$ if and only if $\sum_{i} a_i = T$.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;Use the elementary symmetric polynomial $e_J$ of degree $J$.&lt;&#x2F;li&gt;
&lt;li&gt;By Lucas Theorem $e_{p^i}(a_1,\dots,a_n)\mod p$ equals the $i$th digit in the $p$-ary representation of $\sum_i a_i$.&lt;&#x2F;li&gt;
&lt;li&gt;We can easily check the $p$-ary representation with a $\mod_p$ polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;This is just $p_q(a_1,\dots,a_n) =1 - \prod_{j=0}^{t-1} (1-(c_j -e_{q^i})^{q-1})$.&lt;&#x2F;li&gt;
&lt;li&gt;Doing this for $s,t$ and primes $2,3$ such that $2^s\cdot 3^t&amp;gt;n$ we get the required polynomial.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-of-theorem-3-1&quot;&gt;Proof of Theorem 3.1:&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Let $f$ be our function.&lt;&#x2F;li&gt;
&lt;li&gt;We define $g:[n]\rightarrow {0,1}$ as $f(x)=g(|x|_1)$.&lt;&#x2F;li&gt;
&lt;li&gt;The output gate sums over (a) all possible choices of $T\in [n]$ such that $g(T)=1$ and (b) sums over all ways to partition $T$ into a &lt;em&gt;sum&lt;&#x2F;em&gt; of $\lceil n^{1&#x2F;3}\rceil$ many parts $T_1,\dots,T_{t} \in [T]$.&lt;&#x2F;li&gt;
&lt;li&gt;There are $2^{O(n^{1&#x2F;3}\log n)}$ many choices.&lt;&#x2F;li&gt;
&lt;li&gt;Associate each $T_i$ with a disjoint set $S_i$ of at most $\lceil n^{2&#x2F;3}\rceil$ many input variables.&lt;&#x2F;li&gt;
&lt;li&gt;We want to verify that each $T_i$ the sum over the variables in $S_i$ equals $T_i$.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that there is &lt;em&gt;at most&lt;&#x2F;em&gt; one choice from (a) and (b) that could be consistent with the given input.
&lt;ul&gt;
&lt;li&gt;This is clear, as the sets and size describe it.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we can sum over these choices by using a $\mod_5$ gate, as the value is either $0$ or $1$.&lt;&#x2F;li&gt;
&lt;li&gt;That means we now have a given size $T_i$ and $S_i$. We already checked that $T_i$ corresponds to $|S_i|$ on the second layer.&lt;&#x2F;li&gt;
&lt;li&gt;We now check that the set is correct by an $\mod_6\circ$ $\land$ gate.
&lt;ul&gt;
&lt;li&gt;For this we use Theorem 3.2.&lt;&#x2F;li&gt;
&lt;li&gt;As the polynomial has degree $\sqrt{n}$, we can simulate it by a $\mod_6$ gate over the monomials represented by and $\land$ gate.&lt;&#x2F;li&gt;
&lt;li&gt;As this uses something like Chinese Remainder, we need another $\land$ gate.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This gives us a circuit $\mod_6\circ \mod_5\circ \land \circ \mod_6 \circ \land$.&lt;&#x2F;li&gt;
&lt;li&gt;Now Proposition 2.2 eliminates the $\land$ gate.
&lt;ul&gt;
&lt;li&gt;Note: While this is the original as written in the paper, I do not quite understand the application of it.&lt;&#x2F;li&gt;
&lt;li&gt;However, there is a SYM$\circ\land$ which they reference and gives subexponential size.&lt;&#x2F;li&gt;
&lt;li&gt;The new size of the proposition is then $2^{(\log n)^d}$.&lt;&#x2F;li&gt;
&lt;li&gt;This stays inside the overall size bound.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Proof Sketch of Theorem 1.1:
&lt;ul&gt;
&lt;li&gt;The proof works similar, except that we partition the sum into $n^{1&#x2F;k}$ parts and use Chinese Remainder.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof-of-theorem-1-5&quot;&gt;Proof of Theorem 1.5&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Contraposition: Assume there is some $m=p_1\cdot p_r$ along with depth $d$ such that majority can be computed by depth-$d$ ACC$_0[m]$ circuit of size $\exp(O(n^{\alpha&#x2F;rd}))$.&lt;&#x2F;li&gt;
&lt;li&gt;Let $C$ be a TC$_0$ circuit.&lt;&#x2F;li&gt;
&lt;li&gt;Replace every majority gate with a copy of the assumed circuit.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us a ACC$_0[m]$ circuit of depth at most $cd$ and size $\exp(O(n^{\alpha&#x2F;rd}))$.&lt;&#x2F;li&gt;
&lt;li&gt;By (CP19) every depth $cd$ circuit of size $s$ over $\land,\lor,\mod_m$ gates is equivalent to a SYM$\circ\land$ circuit of size $D&#x27;$ with $2^{(m\log s)^{10rcd}}$.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us the contradiction.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Tight Bounds for the Randomized and Quantum Communication Complexities of Equality with Small Error</title>
        <published>2021-11-16T01:00:00+00:30</published>
        <updated>2021-11-16T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/randomized-computation/"/>
        <id>https://narfinger.github.io/posts/2021/randomized-computation/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/randomized-computation/">&lt;h1 id=&quot;2021-07-25-md-tight-bounds-for-the-randomized-and-quantum-communication-complexities-of-equality-with-small-error&quot;&gt;2021-07-25-MD-Tight Bounds for the Randomized and Quantum Communication Complexities of Equality with Small Error&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2021&#x2F;113&#x2F;&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;I am only going to cover the convertion between public coin protocols to private coin protocols.&lt;&#x2F;li&gt;
&lt;li&gt;This is an improvement over the original Newman&#x27;s Theorem.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem (Neumann): $R_{\epsilon +\delta}^{priv}(F) \leq R_\epsilon^{pub}(F) + \log n&#x2F;\delta^2 + O(1)$.&lt;&#x2F;li&gt;
&lt;li&gt;Result: $\forall \epsilon,\delta$ in sufficient ranges $R_{\epsilon (1 +\delta)}^{priv}(F) \leq R_\epsilon^{pub}(F) + \log n&#x2F;\epsilon + \log 6&#x2F;\delta^2$.
&lt;ul&gt;
&lt;li&gt;This follows similar to Neumann but uses a multiplicative Chernoff bound instead of an additive one.&lt;&#x2F;li&gt;
&lt;li&gt;This seems like a good way to get familiar with this proof.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Let $\Pi$ be a protocol that computes $F$ with error $\epsilon$.&lt;&#x2F;li&gt;
&lt;li&gt;Set $B=6n&#x2F;\delta^2\epsilon$.&lt;&#x2F;li&gt;
&lt;li&gt;Independently choose random strings $r_1,\dots,r_B$ according to the distribution used by $\Pi$.&lt;&#x2F;li&gt;
&lt;li&gt;Let $I_{j,x,y}$ denote the indicator that $r_j$ is a bad random string for $x,y$.&lt;&#x2F;li&gt;
&lt;li&gt;Fix two arbitrary inputs $x,y$. The error probability implies that $\Pr_{r_1,\dots,r_B}[I_{j,x,y}=1] \leq \epsilon$.&lt;&#x2F;li&gt;
&lt;li&gt;Linearity of expecation now gives $E_{r_1,\dots,r_B}[\sum_{j\in B}I_{j,x,y}]\leq B\epsilon =6n&#x2F;\delta^2$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we give an upper bound on $\Pr_{r_1,\dots,r_B}[\sum_{j\in B}I_{j,x,y} \geq B\epsilon(1+\delta)]$.&lt;&#x2F;li&gt;
&lt;li&gt;This can be bounded by Chernoff with $\leq \exp(-\delta^2 6n&#x2F;3\delta^2)=\exp(-2n) &amp;lt; 2^{-2n}$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we union bound over all $x,y$ giving us $Pr[\text{the sum is above B\epsilon(1+\delta) for some x,y}]\leq \sum_{x,y} Pr[...]$&lt;&#x2F;li&gt;
&lt;li&gt;This is bounded by $2^{2n} 2^{-2n}=1$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, there exists a choice of $r_1,\dots,r_B$ that gives the protocol random private coin bits.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Keep that card in mind</title>
        <published>2021-11-11T01:00:00+00:30</published>
        <updated>2021-11-11T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/dealer-guesser/"/>
        <id>https://narfinger.github.io/posts/2021/dealer-guesser/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/dealer-guesser/">&lt;h1 id=&quot;2021-07-08-mn-keep-that-card-in-mind-card-guessing-with-limited-memory-pdf&quot;&gt;2021-07-08-MN-Keep That Card in Mind: Card Guessing with Limited Memory.pdf&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2021&#x2F;096&#x2F;&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;A Dealer deals cards via some strategy from a set of cards labeled by $1,\dots,n$.&lt;&#x2F;li&gt;
&lt;li&gt;Guesser has to guess which card is dealt.&lt;&#x2F;li&gt;
&lt;li&gt;A guesser with perfect memory can guess $\ln n$ correct guesses.
&lt;ul&gt;
&lt;li&gt;The guesser remembers which cards are played and picks randomly from the remaining cards.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;With no memory, the guesser can guess only 1 in expectation.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;results-1&quot;&gt;Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Guesser with $O(\log^2 n)$ bits has a near optimal result (static or random shuffle).&lt;&#x2F;li&gt;
&lt;li&gt;No Guesser with $m$ bits of memory can score better than $O(\sqrt{m})$ correct guesses.&lt;&#x2F;li&gt;
&lt;li&gt;There exists an adaptive dealer for which no guesser with memory $m$ can make more than $\ln m + 2\ln \log n + O(1)$ correct guesses in expectation.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;overview-of-proofs&quot;&gt;Overview of Proofs&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Main result:
&lt;ul&gt;
&lt;li&gt;The guesser tracks from which cards were drawn from multiple subsets.&lt;&#x2F;li&gt;
&lt;li&gt;Every subset card in the subset is &quot;tracked&quot; by at most $2\log n$ bits.&lt;&#x2F;li&gt;
&lt;li&gt;Guesser can recover the last card that has not appeared in each subset and guesses it.&lt;&#x2F;li&gt;
&lt;li&gt;Subsets are build incrementally such that the $i$th subset contains the $i+1$th.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Lower Bound:
&lt;ul&gt;
&lt;li&gt;The lower bound is proven by using correct guesses to encode an ordered set.&lt;&#x2F;li&gt;
&lt;li&gt;The encoding simulates the game and the bottom is the ordered set we wish to encode.&lt;&#x2F;li&gt;
&lt;li&gt;If sufficiently many correct guesses occur we store what is required to encode this game.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us the set.&lt;&#x2F;li&gt;
&lt;li&gt;We store:
&lt;ul&gt;
&lt;li&gt;The memory state of the guesser&lt;&#x2F;li&gt;
&lt;li&gt;The set of turns it predicted correctly&lt;&#x2F;li&gt;
&lt;li&gt;The cards the dealer draws in the other turns with their order.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The memory saving is from turns predicted correctly + state of the guesser.&lt;&#x2F;li&gt;
&lt;li&gt;We also fix the randomness of the guesser overall (not per set) to make this deterministic.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;simple-strategies&quot;&gt;Simple Strategies&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Subset Guessing:
&lt;ul&gt;
&lt;li&gt;Chose a random or predetermined subset of cards $A\in \binom{[n]}{m}$.&lt;&#x2F;li&gt;
&lt;li&gt;Every turn the guesser guesses one card in $A$ that not yet has occured.&lt;&#x2F;li&gt;
&lt;li&gt;This requires $m$ bits to store.&lt;&#x2F;li&gt;
&lt;li&gt;Counting the turns in which the dealer draws cards from $A$ we get that the guesser makes $\ln m$ correct guesses.&lt;&#x2F;li&gt;
&lt;li&gt;$1&#x2F;n + 1&#x2F;(n-1) + 1&#x2F;(n-2) + \dots + 1&#x2F;2 + 1$.&lt;&#x2F;li&gt;
&lt;li&gt;This works against any dealer as these cards have to be drawn at some point in the game.&lt;&#x2F;li&gt;
&lt;li&gt;Because we can predetermine the set and the above fact we do not need to store a description of the set.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Remembering last $k$ cards:
&lt;ul&gt;
&lt;li&gt;Guess the last card by storing the sum $\sum_{i=1}^n i$ and subtract the card shown.&lt;&#x2F;li&gt;
&lt;li&gt;This generalizes via chinese remainder to $k$ cards.&lt;&#x2F;li&gt;
&lt;li&gt;Store $\sum_{i=1}^n i^p \mod n$ for $p=1,\dots, k$ and remove $d^p$ for the shown card $d$.&lt;&#x2F;li&gt;
&lt;li&gt;This requires $k\log n$ bits.&lt;&#x2F;li&gt;
&lt;li&gt;As the set of the last cards is now know, we make $\ln k$ correct guesses.&lt;&#x2F;li&gt;
&lt;li&gt;This works against any dealer.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;less-simple-strategy&quot;&gt;Less Simple Strategy&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;For certain subsets $S_1,\dots,$ store the number of cards seen from this subset and the number as in the remembering last $k$ cards.&lt;&#x2F;li&gt;
&lt;li&gt;The sets will be $[1,2], [1,2,3,4], \dots, [1,\dots,n]$.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;Call a set $S_i = [1,\dots,w]$ useful if the last card that appears in it does not appear in the next subset $S_{i+1}$.&lt;&#x2F;li&gt;
&lt;li&gt;Every subset will contribute a correct guess but it could be that the same guess comes from multiple subsets.&lt;&#x2F;li&gt;
&lt;li&gt;Not so if the subset is useful.&lt;&#x2F;li&gt;
&lt;li&gt;The probability that a subset is useful is $(2w-w)&#x2F;2w$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, the expected number of useful sets is $\log n&#x2F;2$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;lower-bound-argument&quot;&gt;Lower Bound Argument&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Any Guesser using $m$ bits of memory can get at most $O(\min { \ln n, \sqrt{m}})$ correct guesses in expectation against random shuffle dealer.&lt;&#x2F;li&gt;
&lt;li&gt;Compression Argument:
&lt;ul&gt;
&lt;li&gt;Encoding function for ordered set $B$:
&lt;ul&gt;
&lt;li&gt;Simulate the guesser on a deck of cards where the last $k$ cards are $B$ (including order).&lt;&#x2F;li&gt;
&lt;li&gt;Record the memory of the guesser $m$ bits after the first $n-k$ cards.&lt;&#x2F;li&gt;
&lt;li&gt;If the guesser gives $\ell$ correct guesses than we supply the remaining $k-\ell$ guesses (without position).&lt;&#x2F;li&gt;
&lt;li&gt;We note the positions where the guesser was correct.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us a size of $m + \log \binom{k}{\ell} + \log (\prod_{i=0}^{k-\ell-1} n-i)$.&lt;&#x2F;li&gt;
&lt;li&gt;The number of ordered sets is $\prod_{i=0}^{k-1} n-i$.&lt;&#x2F;li&gt;
&lt;li&gt;The probability over the choices of $B$ for any correct guess beyond $\frac{m+1}{\beta \ln n}$ drops exponentially.
&lt;ul&gt;
&lt;li&gt;This comes from comparing the encoding size with the size of the ordered sets.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Now we can use the following Lemma (2.1.5) and prefix freeness of the constructed code.&lt;&#x2F;li&gt;
&lt;li&gt;For every encoding function the probability that the encoding is $d$ bits less than its entropy is at most $2^{-d}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;other-results&quot;&gt;Other Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;For every $m$ there exists an adaptive dealer such that any guesser makes at most $\ln m + 2\ln \log n + O(1)$ correct guesses.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;questions&quot;&gt;Questions&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;All of them seem to have a low probability for some cards.&lt;&#x2F;li&gt;
&lt;li&gt;So can we make a guesser that will have a non negligable probability on all dealers?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Montone Complexity of Spanning Tree Polynomial Re-visited</title>
        <published>2021-11-10T01:00:00+00:30</published>
        <updated>2021-11-10T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/montone-spanning-tree-polynomial/"/>
        <id>https://narfinger.github.io/posts/2021/montone-spanning-tree-polynomial/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/montone-spanning-tree-polynomial/">&lt;h1 id=&quot;2021-09-14-cdgm-monotone-complexity-of-spanning-tree-polynomial-re-visited&quot;&gt;2021-09-14-CDGM-Monotone Complexity of Spanning Tree Polynomial Re-visited&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2109.06941v1&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Spanning Tree polynomial is in VP&lt;&#x2F;li&gt;
&lt;li&gt;Has monotone circuit complexity $2^{\Omega(n)}$.&lt;&#x2F;li&gt;
&lt;li&gt;There are some other results in this paper.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;details&quot;&gt;Details&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Spanning Tree polynomial is sum over edges of spanning tree.&lt;&#x2F;li&gt;
&lt;li&gt;$ST(G&#x27;) = \sum_{t\in T} \prod_{(u,v)\in t, u,v\neq r} x_{u,v}$.&lt;&#x2F;li&gt;
&lt;li&gt;$G&#x27;$ is directed version of an undirected graph (i.e., both edges included).&lt;&#x2F;li&gt;
&lt;li&gt;Here $r$ is the root, i.e., the root is not in the polynomial and assumed to be 1.&lt;&#x2F;li&gt;
&lt;li&gt;The polynomial is given as ordered over $u$ in the paper.&lt;&#x2F;li&gt;
&lt;li&gt;$ST(G)$ can be computed by an ABP via determinant.&lt;&#x2F;li&gt;
&lt;li&gt;Let $G$ be a $d$-regular expander, then every monotone circuit for $ST(G)$ has size at least $2^{\Omega(n)}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Expander Mixing Lemma: Let $G$ be an undirected $d$ regular graph such that $\gamma_2$, the second largest eigenvalue of the adjacency matrix. Then for every set $S,T$ $| |E(S,T)| -\frac{d}{n} |S| |T| | \leq \gamma_2 \sqrt{|S| |T|}$.
&lt;ul&gt;
&lt;li&gt;$E(S,T)$ is the edges in the cut of $S,T$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Matrix Tree Theorem: Let $G$ be an undirected graph and $0,\mu_1,\dots,\mu_{n-1}$ be the eigenvalues of the Laplacian of $G$. Then the number of spanning trees is $1&#x2F;n \mu_1 \cdots \mu_{n-1}$.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 2.1 (Yeh19): Let $p$ be a monotone polynomial. Then we can write $p=\sum_{t=1}^s a_t b_t$ with $n&#x2F;3\leq \supp(a_t) \leq 2n&#x2F;3$ and $\supp(b_t) = [n]\setminus \supp(a_t)$.
&lt;ul&gt;
&lt;li&gt;Here, supp is the variables occurring in the polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;Moreover, the coefficients of any monomial in $a_t b_t$ is bounded by the coefficient of the same monomial in $p$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-1&quot;&gt;Proof&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;We can look at the sum $\sum_{i=1}^s a_i b_i$ into buckets.&lt;&#x2F;li&gt;
&lt;li&gt;Let $X_t={x_{t,i} \mid x_{t,i}\in \supp(a_i)\cup \supp(b_i)}$.&lt;&#x2F;li&gt;
&lt;li&gt;Our buckets now make the computation look like this $\sum_{i=1}^{s&#x2F;(n-1)} \sum_{t=2}^n a&#x27;_i b&#x27;_i$.&lt;&#x2F;li&gt;
&lt;li&gt;Let us study one of the buckets, by fixing $s$ arbitrarily.&lt;&#x2F;li&gt;
&lt;li&gt;We want to have an upper bound of $\sum_{t=2}^n |X_t|$.
&lt;ul&gt;
&lt;li&gt;This will give us a lower bound on the size, as we will count the monomials for this fixed $s$.&lt;&#x2F;li&gt;
&lt;li&gt;If $x_{i,i&#x27;}\in \supp(a_s)$ and $x_{j,j&#x27;}\in \supp(b_s)$ then not $x_{i,j}$ and $x_{j,i}$ can be in $\cup_{t=2}^n X_t$.
&lt;ul&gt;
&lt;li&gt;Otherwise, $x_{i,j}\in \supp(a_s)$ and $x_{j,i}\in \supp(b_s)$.&lt;&#x2F;li&gt;
&lt;li&gt;Otherwise $x_{i,j}x_{j,i}$ would be contained in a monomial of $a_s b_s$.&lt;&#x2F;li&gt;
&lt;li&gt;This is a cycle and hence not allowed in a spanning tree.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that $x_{i,j}$ and $x_{j,i}$ are in $X_i,X_j$ respectively.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This means that at least one of the two directed edges must be absent in $\cup_{t=2}^n X_t$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $\sum_{t=2}^n |X_t| \geq dn - E(a_s,b_s)$ where $E(a_s,b_s)$ is the set of undirected edges.
&lt;ul&gt;
&lt;li&gt;The number of monomials is given by $dn$ for the whole graph.&lt;&#x2F;li&gt;
&lt;li&gt;Except we have $E(a_s,b_s)$ removed from this because one edge is missing from this for every undirected edge this has.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Setting $|a_s|,|b_s| \geq n&#x2F;3$ and $|a_s|+|b_s| =n$ and the expander Lemma we get&lt;&#x2F;li&gt;
&lt;li&gt;$|E(a_s,b_s)| \geq d&#x2F;n n^2&#x2F;9 - \lambda_2 n&#x2F;2 = n(d&#x2F;9 - \lambda_2&#x2F;2)$.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us the number of monomials for one fixed $s$, namely $\leq 1.01d(1-\alpha)^{n-1}$ for a constant $\alpha$.&lt;&#x2F;li&gt;
&lt;li&gt;As the number of monomials in a spanning tree is (in our case) $1&#x2F;n(d-\lambda_2)^{n-1}$.&lt;&#x2F;li&gt;
&lt;li&gt;Our bound is now $(1&#x2F;n (d-\lambda_2)^{n-1})&#x2F; 1.01(1-\alpha)^{n-1}$ which is exponential.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;interesting-open-problems&quot;&gt;Interesting Open Problems&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Is there an explicit polynomial computable by a formula that has exponential monotone circuits?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>The Space Complexity of Sampling</title>
        <published>2021-08-28T01:00:00+00:30</published>
        <updated>2021-08-28T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/space-complexity-of-sampling/"/>
        <id>https://narfinger.github.io/posts/2021/space-complexity-of-sampling/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/space-complexity-of-sampling/">&lt;h1 id=&quot;2021-07-22-cgz-the-space-complexity-of-sampling&quot;&gt;2021-07-22-CGZ-The Space Complexity of Sampling&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2021&#x2F;106&#x2F;&quot;&gt;paper&lt;&#x2F;a&gt;
&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;doi.org&#x2F;10.1145&#x2F;3404858&quot;&gt;GW-A Lower Bound for Sampling Disjoint Sets&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Explicit boolean function that cannot be computed by a width $2^{\Omega(n)}$ read-once branching program but can be easily sampled by ROBPs.&lt;&#x2F;li&gt;
&lt;li&gt;An explicit boolean function such that any distribution by a width $2^{\Omega(n)}$ width ROBP has statistical distance $1&#x2F;2-2^{-\Omega(n)}$ from the uniform distribution.
&lt;ul&gt;
&lt;li&gt;Notice that sampling can be easier than computing.&lt;&#x2F;li&gt;
&lt;li&gt;(x,XOR(x)) is hard to compute by AC0 circuits but (U,XOR(U)) where $U$ is the uniform distribution is easy to sample by AC0 circuits.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Same but with distance to a good code.&lt;&#x2F;li&gt;
&lt;li&gt;Asking questions similar to Viola20 answered but in the limited space model.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;proof-overview&quot;&gt;Proof Overview&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Two models:&lt;&#x2F;li&gt;
&lt;li&gt;Complex Samplers:
&lt;ul&gt;
&lt;li&gt;ROBPs without input where every vertex can have an arbitrary number of outputs.&lt;&#x2F;li&gt;
&lt;li&gt;Every vertex has a distribution.&lt;&#x2F;li&gt;
&lt;li&gt;Every edge is also denoted by a label $0,1$.&lt;&#x2F;li&gt;
&lt;li&gt;The sampled output is taking a random walk (according to the distributions) and the concatenated labels.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Complex Samplers and ROBP are equivalent up to small loss in parameters with same width restriction (for sampling).
&lt;ul&gt;
&lt;li&gt;This is proven in Theorem 6&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Simple Samplers:
&lt;ul&gt;
&lt;li&gt;Simple Samplers are Complex Samplers where the outgoing degree of every vertex is at most 2.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Simple Samplers are the same as &lt;em&gt;computing&lt;&#x2F;em&gt; with ROBP (on uniform input distribution).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;example-for-theorem-1&quot;&gt;Example for Theorem 1&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Address function: Take input $x||a$ with $a=\log |x|$ and size $n=k+\log k$ and output $x_{\text{bin}^{-2}(a)}$.
&lt;ul&gt;
&lt;li&gt;This function separates read-once and read-twice branching programs.&lt;&#x2F;li&gt;
&lt;li&gt;Also separates simple and complex samplers.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Simple samplers cannot the distribution $(U_n, address(U_n))$.
&lt;ul&gt;
&lt;li&gt;Assume the width is $2^k-1$&lt;&#x2F;li&gt;
&lt;li&gt;There is a single unique path for every output.&lt;&#x2F;li&gt;
&lt;li&gt;At layer $V_k$ there must be two different sequences of bits $x,y\in {0,1}^k$ that lead to the same vertex $v\in V_k$.
&lt;ul&gt;
&lt;li&gt;Because of the width restriction.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;But $x,y$ differ at some coordinate which could be exactly the width it produces.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Complex Samplers can sample this distribution in width $O(n)$.
&lt;ul&gt;
&lt;li&gt;It is a convex combination of $2k$ distributions.&lt;&#x2F;li&gt;
&lt;li&gt;Fix such that $x_a\in {0,1}$.&lt;&#x2F;li&gt;
&lt;li&gt;Now every distribution is easy, fix $a$ and the bit $x_a$ and draw everything else at random.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that the target distribution is uniformly drawn by first picking a distribution as above and then draw the distribution.&lt;&#x2F;li&gt;
&lt;li&gt;Any collection of $2k$ distributions that can be sampled in width 1 can be sampled by width $2k$ in a complex sampler.
&lt;ul&gt;
&lt;li&gt;Just have a deciding vertex at the start that samples uniformly these.&lt;&#x2F;li&gt;
&lt;li&gt;As every vertex needs an output bit, contract the first two edges together.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;gv-pseudorandom-bits-for-oblivious-branching-programs&quot;&gt;GV - Pseudorandom Bits for Oblivious Branching Programs&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Questions:&lt;&#x2F;strong&gt;
&lt;ul&gt;
&lt;li&gt;What if the address function is $a||x$ instead?
&lt;ul&gt;
&lt;li&gt;Then the width is obviously maximal $n$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Notice that the following does not work.
&lt;ul&gt;
&lt;li&gt;Sample the first bit $a_1$. If this is zero, sample $x_1,\dots,x_{k-1}$ bits independently&lt;&#x2F;li&gt;
&lt;li&gt;Otherwise, sample $a_2$ and recurse.&lt;&#x2F;li&gt;
&lt;li&gt;At every point we can sample $x_1,\dots,x_{k-1}$ independently and hence save.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us a skew binary tree which has still width $\Omega(2^d)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;It is unclear if a lower bound for any function exist that works for every order (not necessarily for address).
&lt;ul&gt;
&lt;li&gt;The lower bound works by using the Computation equal to Simple Samplers argument.&lt;&#x2F;li&gt;
&lt;li&gt;The Computation is actually a lower bound for oblivious read-k branching program.&lt;&#x2F;li&gt;
&lt;li&gt;Oblivious, as in the ABP sense, i.e., the program has in every layer only one variable it reads and this does not depend on values it read so far.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Nissan-Widgerson Generator seems to be, however, independent of the order.
&lt;ul&gt;
&lt;li&gt;The Nissan-Widgerson Generator is about a Turing Machine that visits every cell at most $d$ times.&lt;&#x2F;li&gt;
&lt;li&gt;An argument about the sequences shows the lower bound.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits</title>
        <published>2021-06-16T01:00:00+00:30</published>
        <updated>2021-06-16T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2021/superpolynomial-lower-bounds-against-low-depth-algebraic-circuits/"/>
        <id>https://narfinger.github.io/posts/2021/superpolynomial-lower-bounds-against-low-depth-algebraic-circuits/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2021/superpolynomial-lower-bounds-against-low-depth-algebraic-circuits/">&lt;h1 id=&quot;2021-06-14-lst-superpolynomial-lower-bounds-against-low-depth-algebraic-circuits&quot;&gt;2021-06-14-LST-Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2021&#x2F;081&#x2F;&quot;&gt;paper&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;results&quot;&gt;Results&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;First superpolynomial lower bound against constant depth circuit for arbitrary depth.&lt;&#x2F;li&gt;
&lt;li&gt;General Circuits&lt;&#x2F;li&gt;
&lt;li&gt;Better bound against IMM for set multilinear circuits, namely $n^{d^{\exp(-\Delta)}}$ vs $f(d)\poly(n^2)$. (Theorem 2)
&lt;ul&gt;
&lt;li&gt;For large $d$ and small $\Delta$ this is stricly better.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Convert any constant depth circuit to a constant depth set-multilinear circuit. (Lemma 10)&lt;&#x2F;li&gt;
&lt;li&gt;Formal: Let $d=o(\log N)$ and $\mathbb{F}$ be characteristic zero or greater than $d.&lt;&#x2F;li&gt;
&lt;li&gt;=&amp;gt; There exists an explicit formal polynomial $P_{N,d}(x_1,\dots,x_N)$ that has no algebraic circuits of product depth $\Delta$
&lt;ul&gt;
&lt;li&gt;and size at most $N^{d^{\exp(-\Delta)}}$.&lt;&#x2F;li&gt;
&lt;li&gt;The polynomial is the IMM on $dn^2$ variables.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that this bound scales with $\Delta$ and the polynomial is independent of $\Delta$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;setup&quot;&gt;Setup&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;$w=(w_1,\dots,w_d)$ are weight vectors in $\mathbb{Z}\setminus {0}$.&lt;&#x2F;li&gt;
&lt;li&gt;$w_S=\sum_{i\in S} w_i$, $P_w$ is all indices that have positive weight and $N_w$ all indices that have negative weight.&lt;&#x2F;li&gt;
&lt;li&gt;$w$ is $b$-unbiased if $|w_I| \leq b$ for all interval $I\subseteq [d]$.
&lt;ul&gt;
&lt;li&gt;This implies $w_i\leq b$ (I think also $w_i\leq b&#x2F;d$).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Complexity measure:
&lt;ul&gt;
&lt;li&gt;For a given $w$ we take a matrix such that the rows are indexed by all possible monomials on the positive variables and the columns by all possible monomials on the negative variables.&lt;&#x2F;li&gt;
&lt;li&gt;The entry $(m_1,m_2)$ is the coefficient of $m_1m_2$ in $f$.&lt;&#x2F;li&gt;
&lt;li&gt;We define this as $M_w(f)$.&lt;&#x2F;li&gt;
&lt;li&gt;The measure is now the rank of $M_w(f)$ divided by the maximal possible rank,i.e, $rank(M_w(f))&#x2F;\sqrt{ |M^P_w| |M^N_w| }$&lt;&#x2F;li&gt;
&lt;li&gt;This is equal to $rank(M_w(f))&#x2F;2^{1&#x2F;2 \sum_i |w_i| }$.&lt;&#x2F;li&gt;
&lt;li&gt;The usual properties hold.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;What is the main idea behind this measure?
&lt;ul&gt;
&lt;li&gt;I think this is just splitting the variables depending on the weight given, i.e., if it is positive or not.&lt;&#x2F;li&gt;
&lt;li&gt;This is in essence just partial derivatives to with respect to the negative set.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Variables in set $X_i$ are labelled by ${0,1}^{ |w_i| }$.
&lt;ul&gt;
&lt;li&gt;Notice that the number of variables is also depending on the weight vector $w=(w_1,\dots,w_d)\in (\mathbb{Z}\setminus {0})^d$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The polynomial is now $P_w = \sum_{\sigma(m_+) \text{prefix} of \sigma(m_-) \text{or other way}} m$.
&lt;ul&gt;
&lt;li&gt;Here $\sigma(m_+)$ is the variable bit string of the positive monomial and $\sigma(m_-)$ of the negative monomial.&lt;&#x2F;li&gt;
&lt;li&gt;The variable bit string is just the bit string of the variables chosen as above.&lt;&#x2F;li&gt;
&lt;li&gt;This is still parameterized by $m$.&lt;&#x2F;li&gt;
&lt;li&gt;$w$ being $b$-unbiased will be the focus.&lt;&#x2F;li&gt;
&lt;li&gt;This is probably full rank because it looks like a triangle matrix.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;transforming-the-circuit&quot;&gt;Transforming the Circuit&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Let $s\geq Nd$ and $C$ be a homogeneous circuit of size at most $s$ and product depth $\Delta$.&lt;&#x2F;li&gt;
&lt;li&gt;=&amp;gt; Then there is a set multilinear circuit of size at most $(d!)s$ and product depth at most $\Delta$ computing the same polynomial with $|X_i|\leq N$.&lt;&#x2F;li&gt;
&lt;li&gt;Proof Idea:
&lt;ul&gt;
&lt;li&gt;For every subset of variables create a new variable.&lt;&#x2F;li&gt;
&lt;li&gt;Split the gates into every possible subsets of size up to degree of the gate.&lt;&#x2F;li&gt;
&lt;li&gt;Addition gates and leaves are easy.&lt;&#x2F;li&gt;
&lt;li&gt;Product gates now have all possible decompositions.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;lower-bound&quot;&gt;Lower Bound&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Claim 14: Any product depth 2 circuit with $w\in {-k, \lfloor k-k&#x2F;\sqrt{d}}$ has relrank$\leq s 2^{-k\sqrt{d}&#x2F;s}$.
&lt;ul&gt;
&lt;li&gt;Notice that $w_i$ only has two possibilities.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;We can define $C=C_1 + \dots + C_t$ with $C_i$ of the form $\prod\sum\prod\sum$.&lt;&#x2F;li&gt;
&lt;li&gt;Define Type 1 if $C_i$ has degree $\geq \sqrt{d}&#x2F;2$ and Type 2 otherwise.&lt;&#x2F;li&gt;
&lt;li&gt;Type 1 is easy.&lt;&#x2F;li&gt;
&lt;li&gt;For Type 2 it turns out that $|w^{ij}&lt;em&gt;{S_j}| \geq k\deg(C&lt;&#x2F;em&gt;{i,j})&#x2F;2\sqrt{d}$ (the sum of its entries).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Claim 16: Any set multilinear formula of product depth $\Delta$ for $w$ between $\alpha k$ and $-k$ has relrank at most $s2^{-kd^{1&#x2F;(2^\Delta -1)}&#x2F;20}$.
&lt;ul&gt;
&lt;li&gt;Proof similar to Claim 13 and via induction.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Lower Bounds for Monotone Arithmetic Circuits via Communication Complexity</title>
        <published>2020-11-11T01:00:00+00:30</published>
        <updated>2020-11-11T01:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2020/monotone-lowerbounds-from-communication/"/>
        <id>https://narfinger.github.io/posts/2020/monotone-lowerbounds-from-communication/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2020/monotone-lowerbounds-from-communication/">&lt;h1 id=&quot;paper&quot;&gt;Paper&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;eccc.weizmann.ac.il&#x2F;report&#x2F;2020&#x2F;166&#x2F;&quot;&gt;Chattopadhyay, Datta, Mukhopadhyay - Lower Bounds for Monotone Arithmetic Circuits via Communication Complexity&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;While the paper uses probabilities that are scaled by their support to always be correct, we will ignore this scaling for clarity. For details please check the original source.&lt;&#x2F;li&gt;
&lt;li&gt;This text also switches between $m$ being a monomial and a number sometimes.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;There is a polynomial that has depth 3 arithmetic circuits of size $O(nm^4)$ and every polynomial of this type needs $2^{\Omega(\sqrt{n})}$ size monotone circuits.
&lt;ul&gt;
&lt;li&gt;This is the first constant depth vs monotone circuit bound.&lt;&#x2F;li&gt;
&lt;li&gt;All other known bound have to go via depth reduction and hence will have size $2^{\sqrt{d}\log n}$ which is $\Theta(n)$ for&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Both $F_{n,m} -\varepsilon  P$ and $F_{n,m} + \varepsilon P$ have monotone circuit complexity $2^{\Omega(m)}$. Here $F_{n,m} = \prod_{i=1}^n (x_{i,1} + \dots + x_{i,m})$ and $P=P_{n,m}^{\mod 3} = \sum_{\sigma:[n]\rightarrow [m], \mod 3(\oplus(\sigma) = 0)} \prod_{i=1}^n x_{i,\sigma(i)}$.
&lt;ul&gt;
&lt;li&gt;Hrubes recently showed how to show hardness against general arithmetic circuits.&lt;&#x2F;li&gt;
&lt;li&gt;He showed that if $f$ is computed efficiently by general arithmetic circuits than $(1+\sum_i x_i)^d + \varepsilon f$ has efficient monotone circuits.&lt;&#x2F;li&gt;
&lt;li&gt;This is theorem is a first step at proving similar bounds to what we need for Hrubes argument but is not quite the same.&lt;&#x2F;li&gt;
&lt;li&gt;We transfer lower bounds on communication complexity (on a certain rectangle we cannot control) to polynomials that are given by multiplication of two polynomials with coefficients being at most one.&lt;&#x2F;li&gt;
&lt;li&gt;This is similar to rank bounds, compare $\sum_{i} g_i h_i$, if the matrix has high rank than the non-commutative complexity is high.&lt;&#x2F;li&gt;
&lt;li&gt;Here, however, we deal with a more complex measure (corruption) and monotone computation.&lt;&#x2F;li&gt;
&lt;li&gt;From this, we use Lemma 4.1 to give us a connection between the measure $W$ and a function that fulfills $W(\alpha \beta \cap \mathcal{K}(f^{-1}(z))) \leq \gamma W(\alpha\beta)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;definitions&quot;&gt;Definitions&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;For a given set multilinear polynomial with variables $X = \cup_i X_i = \cup_i \lbrace x_{i,1},\dots, x_{i,m}\rbrace$ we define $\sigma:[n]\rightarrow [m]$ with $\sigma(i)=j_i$, i.e., the $j$th variable in the set $i$ for a given monomial $m$. (The function should probably be called $\sigma_m$.)
&lt;ul&gt;
&lt;li&gt;This forms a bijection between the space of all functions $[n]\rightarrow [m]$ ($\mathcal{F}_{n,m}$) and the set of all set multilinear monomials.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Parity set vectors: Define the parity set vector for $m$, $\oplus(m)\in \lbrace 0,1\rbrace ^m$ where the $j$th entry is $|\sigma^{-1}(j)| \mod 2$, i.e., how many variables $x_{i,j}$ for a fixed $j$ exist $\mod 2$.&lt;&#x2F;li&gt;
&lt;li&gt;We define for a subset $S\subseteq \lbrace 0,1\rbrace^m$ $K(S)=\lbrace m \mid \oplus(m)\in S\rbrace$. This just takes all monomials that are compatible with a set $S$.&lt;&#x2F;li&gt;
&lt;li&gt;Rectangular corruption: We assume familiarity with rectangles and communication complexity. $Corr_{\lambda,\varepsilon}^z(F) = \min_{\lbrace R, \Pr_\lambda [R\cap F^{-1}(z)]\leq \varepsilon\Pr_\lambda [R]\rbrace} \log(1&#x2F;\Pr_\lambda [R])$.
&lt;ul&gt;
&lt;li&gt;Here $\Pr_\lambda [R]$ is the probability that an element under the distribution $\lambda$ is in $R$.&lt;&#x2F;li&gt;
&lt;li&gt;The intutition behind this measure is that $F$ is hard (has large communication complexity) if finding rectangles that are approximately monochromatic is hard.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Small bias spaces: A multiset $\mathcal{B}\subseteq \lbrace -1,+1\rbrace ^m$ is called an $\varepsilon$-biased space if for every $S$ $1&#x2F;N \sum_{b\in \mathcal{B}}\prod_{i\in S} b_i \leq \varepsilon$.
&lt;ul&gt;
&lt;li&gt;I.e., no matter which $S$ we take, $B$ has still small bias under the projection to $S$.&lt;&#x2F;li&gt;
&lt;li&gt;There are deterministically constructable spaces.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;SINK is the following boolean function: Given a boolean vector $\binom{m}{2}$, define a complete directed graph with this for a vector $x_{i,j}=1$ then $v_i\rightarrow v_j$, otherwise $v_i \leftarrow v_j$.
&lt;ul&gt;
&lt;li&gt;SINK$(x)=1$ if there is a sink in the graph.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;A monomial $m$ is called a sink monomial if $SINK(\vec{\oplus}(m))=1$.&lt;&#x2F;li&gt;
&lt;li&gt;We call a polynomial a non-sink polynomial if it is completely supported on non-sink monomials.&lt;&#x2F;li&gt;
&lt;li&gt;We call a polynomial a $\delta$-non-sink polynomial if every monomial&#x27;s $m$ coefficient $\alpha$ lies in the interval $[0,\delta]$ otherwise it lies in the interval $[1-\delta, 1]$.
&lt;ul&gt;
&lt;li&gt;I think: With our transfer theorem, we can show that for any function $f$ that has large rectangular corruption, then the polynomial that is supported on exactly the $f(\vec{\oplus})=0$ has large monotone complexity.&lt;&#x2F;li&gt;
&lt;li&gt;Except this is not quite true, it needs to be hard for $f\circ XOR$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;the-measure&quot;&gt;The measure&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Basics:
&lt;ul&gt;
&lt;li&gt;We define $\lambda = \mu(x\oplus y)$.&lt;&#x2F;li&gt;
&lt;li&gt;Define the measure $W$ of a monomial $\kappa$ as $\mu(\vec{\oplus}(\kappa)) \cdot 2^m&#x2F;m^n$. Remember that $\vec{\oplus}$ here is the parity vector
&lt;ul&gt;
&lt;li&gt;Notice that the scaling is needed in bounding the summation which stems from the constraints in the optimization problem in the proof.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;We define the measure $W$ of a polynomial via extending it linearily.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Question&lt;&#x2F;strong&gt; This measure is kind of weird because of parity vectors, perhaps there is something easier we can do?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 4.1: If a balanced product polynomial $H=\alpha \cdot \beta$ with coefficients at most one. If this satisfies $W(H\cap \mathcal{K}(f^{-1}(z))) \leq \eta &#x2F;3 W(H)$. Then $W(H)\leq \Omega(2^{-\min Corr_{\lambda,\eta}^z}(f\circ XOR))$.
&lt;ul&gt;
&lt;li&gt;Proof:&lt;&#x2F;li&gt;
&lt;li&gt;Let $u=\lbrace 0,1\rbrace ^m$, $\tilde \alpha[u] = \sum_{\kappa \in \oplus(\kappa)=u} \alpha[\kappa]$. We sum over all coefficients of monomials that have the parity vector equal to $m$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we can write $\alpha \beta$ as $\left(\sum_{u\in \lbrace 0,1\rbrace ^m} \sum_{\kappa \in \oplus(\kappa)=u} \alpha[\kappa] \kappa \right) \cdot \left(\sum_{v\in \lbrace 0,1\rbrace ^m} \sum_{\kappa&#x27; \in \oplus(\kappa&#x27;)=u} \beta[\kappa&#x27;] \kappa \right)$.&lt;&#x2F;li&gt;
&lt;li&gt;This is equal to $\sum_{x\in \lbrace 0,1\rbrace ^m} \left( \sum_{u\in \lbrace 0,1\rbrace ^m} \left( \sum_{\kappa \in \oplus(\kappa)=u} \alpha[\kappa] \kappa \right) \cdot  \left( \sum_{\kappa&#x27; \in \oplus(\kappa&#x27;)=u\oplus x} \beta[\kappa&#x27;] \kappa&#x27; \right) \right)$ as we can obviously replace $w$ with a xor with $u$.&lt;&#x2F;li&gt;
&lt;li&gt;For the next notice that our measure on this is equal to $\sum_{x\in \lbrace 0,1\rbrace ^m} \sum_{\kappa \in \oplus(\kappa)=u} \sum_{\kappa \in \oplus(\kappa&#x27;)=u\oplus x} W(\kappa)\cdot \kappa&#x27;$ if we ignore coefficients.
&lt;ul&gt;
&lt;li&gt;But this is now equal to (by abusing notation a lot) $W(u\oplus (u\oplus x))$. Notice that $W(m\cdot m&#x27;)$ with vectors $\oplus(m)=u,\oplus(m&#x27;)=u&#x27;$ is exactly $u\oplus u&#x27;$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we can write this as $W(\alpha \beta) = \sum_{x\in \lbrace 0,1\rbrace ^m} W(\kappa&#x27;&#x27;) \left(\sum_{u\in \lbrace 0,1\rbrace ^m} \left(\sum_{\kappa \in \oplus(\kappa)=u} \alpha[\kappa]\right) \left(\sum_{\kappa&#x27; \in \oplus(\kappa)=u&#x27;} \beta[\kappa&#x27;]\right)\right)$ where $W(\kappa&#x27;&#x27;)=x$.&lt;&#x2F;li&gt;
&lt;li&gt;Now with our new notation this is equal to $\sum_{x\in \lbrace 0,1\rbrace ^m} W(\kappa&#x27;&#x27;) \sum_{u\in \lbrace 0,1\rbrace } \tilde\alpha[u] \tilde\beta[u\oplus x]$.&lt;&#x2F;li&gt;
&lt;li&gt;We denote this sum as $W(\tilde\alpha,\tilde\beta)$ and $W_z(\tilde w\alpha, \tilde\beta)$ if we enforce that $f(x)=z$.&lt;&#x2F;li&gt;
&lt;li&gt;There is a optimization problem $B$ which maximizes $\tilde W(\alpha,\beta)$ with constraints $0\leq \alpha[u] \leq 4m^{\lvert I(\alpha)\rvert}$ and similar for $\beta[v]$.
&lt;ul&gt;
&lt;li&gt;This follows from a corollary I skip.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;For an optimal solution to $B$, we can see that all except one $\alpha^{*},\beta^{*}$ have to be either $0$ or $4m^{\lvert I(\alpha)\rvert}$ ($\beta$, respectively).&lt;&#x2F;li&gt;
&lt;li&gt;Now we can define a rectangle that is all $u,v$ such that $\alpha[u]\neq 0$ and $\beta[v]\neq 0$ and removing the optimal solution.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we can bound the overall weight by the following sums: The sum of all $u,v$ in the rectangle, the sum of $v$ outside the rectangle and $u$ arbitrary and the sum of $u$ outside the rectangle and $u$ arbitrary.
&lt;ul&gt;
&lt;li&gt;We upper bound the last two by using the optimal solution, i.e., $u^{*}$ and $v^{*}$.&lt;&#x2F;li&gt;
&lt;li&gt;The optimal solution might be a good upper bound already but does not have anything to do with the rectangle.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This is just $\sum_{u\in A,v\in B} \alpha^{*}[u]\beta^{*}[v] W(u\oplus v)$. The rest follows from the upper bounds given by our optimization program and and inserting the definition of the measure.&lt;&#x2F;li&gt;
&lt;li&gt;The other two summation can be upper bounded in a similar fashion where the sum over $W(u^{*} \oplus v)$ is upper bounded by $1$ as $\mu$ is a probability measure.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Corollary 4.1&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;construction-of-depth-3-formulas-monotone-lowerbound&quot;&gt;Construction of depth 3 formulas monotone lowerbound&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;We look at the function $SINK \circ XOR$.&lt;&#x2F;li&gt;
&lt;li&gt;We define the distribution $\mu$ as follows:
&lt;ul&gt;
&lt;li&gt;With probability $1&#x2F;2$ sample a vertex $i\in [k]$ at random and sample randomly an $x$ under the condition that $i$ is a sink. Otherwise, with probability $1&#x2F;2$ sample $x$ at random.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Define $\lambda =\mu(x\oplus y)$.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 5.2 (Lemma from [CMS20]): Corr$_{\lambda,\mu}^1(SINK\circ XOR) = \Omega(\sqrt{m})$.&lt;&#x2F;li&gt;
&lt;li&gt;Proof of the lower bound:
&lt;ul&gt;
&lt;li&gt;Let $Q$ be a $\delta$-non sink polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;By common structure theorem (Theorem 2.1) we can write $Q=\sum_{i=1}^s m_i m&#x27;_i$.&lt;&#x2F;li&gt;
&lt;li&gt;We take the measure $W$ described in Lemma 4.1.&lt;&#x2F;li&gt;
&lt;li&gt;$W(Q\cap \mathcal{K}(SINK^{-1}(1))) = \sum_{i=i}^s W(\alpha_i \beta_i \cap \mathcal{K}(SINK^{-1}(1)))$ (by linearity)&lt;&#x2F;li&gt;
&lt;li&gt;$\geq \sum_{i=1}^t \nu&#x2F;3 W(\alpha_i \beta_i) -48 s 2^{-Cor_{\lambda, nu}(SINK \circ XOR)}$ by Corollary 4.1
&lt;ul&gt;
&lt;li&gt;Notice that Theorem 2.1 gives us the bound on the coefficients.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hence, solving $48 s 2^{-Cor_{\lambda, \nu}(SINK \circ XOR)} \geq \nu&#x2F;3 W(Q) - W(Q\cap SINK^{-1}(1))$ gives us a lowerbound.
&lt;ul&gt;
&lt;li&gt;$W(Q\cap SINK^{-1}(1))\leq 4\delta$.&lt;&#x2F;li&gt;
&lt;li&gt;$W(Q)\geq (1-\delta)&#x2F;3$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence $s\geq ~ 2^{Cor_{\lambda, \nu}(SINK \circ XOR)}$ which is $2^{\sqrt{m}}$ by Theorem 5.2.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>A Lower Bound on Determinantal Complexity</title>
        <published>2020-10-23T05:00:00+00:30</published>
        <updated>2020-10-23T05:00:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2020/lowerbound-determinant/"/>
        <id>https://narfinger.github.io/posts/2020/lowerbound-determinant/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2020/lowerbound-determinant/">&lt;h1 id=&quot;paper&quot;&gt;Paper&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2009.02452&quot;&gt;Kumar, Volk - A Lower Bound on Determinantal Complexity&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;results&quot;&gt;Results&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Determinantal Complexity of $f$: Smallest dimension of a matrix $M$ filled with affine linear forms such that $\det(M)$ computes $f$.&lt;&#x2F;li&gt;
&lt;li&gt;Determinantal Complexity of $\sum_{i=1}^n x_i^n$ is $1.5n -3$.&lt;&#x2F;li&gt;
&lt;li&gt;Permanent has determinantal complexity $(n-1)^2 +1$ (over reals). This is the same as the number of variables in Perm.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;proof-overview&quot;&gt;Proof Overview&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Let $M$ be a $m\times m$ matrix that computes $f=\sum_{i=1}^n x_i^n$.&lt;&#x2F;li&gt;
&lt;li&gt;Converting the matrix into normal form.
&lt;ul&gt;
&lt;li&gt;The constnat part of the matrix (i.e., $M_0 = M(0)$) can be assumed to be diagonal matrix of rank $m-1$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Determinantal Complexity of high degree polynomials.
&lt;ul&gt;
&lt;li&gt;If $M$ has entries being polynomials of degree $n-1$ and $M$ is in normal form and $det(M)=f$, then $m\geq n&#x2F;2$.&lt;&#x2F;li&gt;
&lt;li&gt;The same holds for any polynomial $(\sum_{i=1}^n x_i^n)(1+Q)$ with $Q(0)=0$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Trading Dimension of the Matrix as Degree
&lt;ul&gt;
&lt;li&gt;If there is an $m\times m$ matrix with affine functions and $det(M)=f$, then there is a matrix $N$ of dimension $(m-n+2)\times (m-n+2)$ whose entries are polynomials of degree at most $n-1$.&lt;&#x2F;li&gt;
&lt;li&gt;Normal form keeps intact.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Now the lowerbound from $1$ implies that $m\geq n&#x2F;2$, hence that $m&#x27;-n -2 \geq n&#x2F;2$ with degree $n-1$. Hence $m&#x27;\geq 3n&#x2F;2 -3$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;needed-lemmas&quot;&gt;Needed Lemmas&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Lemma 3.1: Let $P_1,\dots, P_t, Q_1,\dots, Q_t$ be polynomials that have a common root and $R$ be polynomials such that $\deg(R) &amp;lt;d$ and $\sum_{i=1}^n x_i^d = R+ \sum_{j=1}^t P_j Q_j$. Then $t&amp;gt;n&#x2F;2$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 3.8: Let $\begin{pmatrix} A&amp;amp; B\ C&amp;amp; D\end{pmatrix}$. Then $\det(M)=\det(A-BD^{-1}C)\det(D)$.
&lt;ul&gt;
&lt;li&gt;Proof:&lt;&#x2F;li&gt;
&lt;li&gt;$\begin{pmatrix} A&amp;amp; B\ C&amp;amp; D\end{pmatrix} = \begin{pmatrix} A-BD^{-1}C&amp;amp; BD^{-1}\ 0&amp;amp; I_{m-t}\end{pmatrix} = \begin{pmatrix} I_t &amp;amp; 0\ C&amp;amp; D\end{pmatrix}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;second-part&quot;&gt;Second Part&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Lemma 3.9: If $\deg(M)\leq d-1$, additionally $M$ at $(1,1)$ is zero and one on the diagonal and the constant part is diagonal and $\det(M)= f \cdot (\beta + Q)$ where $\beta\neq 0$ and $Q$ constant free.&lt;&#x2F;li&gt;
&lt;li&gt;Then $m\geq n-1$.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:&lt;&#x2F;li&gt;
&lt;li&gt;Using the Laplace expansion gives us  $\det(M)= \sum_{j=1}^m (-1)^{j+1} M_{1.j} \det(N_{1,j})$ where $N_{i,j}$ is the submatrix of deleting the $i$th row and $j$th column.&lt;&#x2F;li&gt;
&lt;li&gt;Claim: $\det(N_{1,j})$ is a constant free polynomial for $j&amp;gt;1$.
&lt;ul&gt;
&lt;li&gt;$N_{1,j}$ has at most $m-2$ non-zero entries
&lt;ul&gt;
&lt;li&gt;$M_0$ has at most $m-1$ non-zero entries by assumption.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;$N_{1,1}(0)$ is the identity matrix.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $\det(N_{1,1})=1 + P(X)$ with $P(X)$ being constant free.&lt;&#x2F;li&gt;
&lt;li&gt;We can write $f (beta + Q) = \det(M) = \sum_{j=1}^m (-1)^{j+1} M_{1,j} \det(N_{1,j}) = M_{1,1}\cdot (1+P) + \sum_{j=2}^m (-1)^{j+1} M_{1,j} \det(N_{1,j})$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $f (beta + Q) = M_{1,1} + M_{1,1} \cdot P  + \sum_{j=2}^m (-1)^{j+1} M_{1,j} \det(N_{1,j})$.&lt;&#x2F;li&gt;
&lt;li&gt;Now $\sum_{i=1}^n x_i^n = 1&#x2F;\beta (- Q(\sum_{i=1}^n x_i^n)+ M_{1,1} + M_{1,1}P + \sum_{j=2}^m (-1)^{j+1} M_{1,j}\det(N_{1,j}))$.&lt;&#x2F;li&gt;
&lt;li&gt;Since $\deg(M_{1,1})&amp;lt;d$ (per entry) and all other polynomials are constant free (have the common root 0), we can apply Lemma 3.1.
&lt;ul&gt;
&lt;li&gt;Notice that our requirement says that the constant part of $M$ at $(1,1)$ needs to be zero (which is a requirement) and as the constant part of $M$ is a diagonal matrix, all $M_{1,j}$ are zero.&lt;&#x2F;li&gt;
&lt;li&gt;The requirement coming from the proof is much less than required, as we only need to find a laplace decomposition where $M_{i,j}$ and $N_{i,j}$ are zero.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;third-part&quot;&gt;Third Part&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Let $M$ be a $m\times m$ matrix.&lt;&#x2F;li&gt;
&lt;li&gt;Let $D_t$ be the principal minor of $M$ which is obtained by deleting the first $m-t$ rows and columns.&lt;&#x2F;li&gt;
&lt;li&gt;$D_t$ is invertible for all $t\leq m-1.
&lt;ul&gt;
&lt;li&gt;$\det(D_t)$ is non-zero as $D_t(0)$ is the identity matrix (by constant requirement). This is then implied by $\det(D_t(0))\neq 0$.&lt;&#x2F;li&gt;
&lt;li&gt;As every entry in $M$ has degree one and $\det(M)$ has degree $n$, $m\geq n$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $D_{n-2}$ is invertible.&lt;&#x2F;li&gt;
&lt;li&gt;Let $M=\begin{pmatrix} A&amp;amp; B\ C&amp;amp; D\end{pmatrix}$.&lt;&#x2F;li&gt;
&lt;li&gt;By Lemma 3.8 $\det(M) = \det(A-BD^{-1}C) \det(D)$.&lt;&#x2F;li&gt;
&lt;li&gt;Since $D^{-1} = adj(D)&#x2F;\det(D)$ where $adj(D)$ is the adjugate of $D$.
&lt;ul&gt;
&lt;li&gt;The adjugate is given by: the entry of $\adj(A)_{i,j}$ is the $j,i$th minor of $A$ times $(-1)^{i+j}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Now the entries of $D^{-1}$ can be written a a ratio of two polynomials where the denominator has degree at most $n-2$ and the numerator has degree at most $n-3$.
&lt;ul&gt;
&lt;li&gt;As the minor removes at least one row&#x2F;column and hence one linear form.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Now the entries of $A-BD^{-1}C$ are given by polynomials with the following maximum degree (in order) $1,1, n-3&#x2F;n-2, 1$.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us that the entries have degree $1+n-3+1$ in the numerator and $n-2$ in the denominator.&lt;&#x2F;li&gt;
&lt;li&gt;This also implies that $A-BD^{-1}C$ is a $(m-n+2) \times (m-n+2)$ matrix.
&lt;ul&gt;
&lt;li&gt;The reason is that $\det(M)$ is a degree $m$ polynomial and $\det(D)$ is a degree $n-1$ polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $\det(A-BD^{-1}C$ has to produce a degree $m-n+2$ polynomial.&lt;&#x2F;li&gt;
&lt;li&gt;As $A,B,C$ have only linear forms, this means the matrix size has to be at least $(m-n+2) \times (m-n+2)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The denominator now gets cleared by the additional multiplication of $\det(D)$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we can have a matrix $N$ that is givey by $(A-BD^{-1}C) \det(D)$ that has entries of degree at most $n-1$.&lt;&#x2F;li&gt;
&lt;li&gt;Let $\det(D)=1+Q$.&lt;&#x2F;li&gt;
&lt;li&gt;Then we can write $\det(M) (1+Q)^{m-n+2} = \det(N) (1+Q)$ where $N$ is the matrix $A-BD^{-1}C$ multiplied every entry with $1+Q$.
&lt;ul&gt;
&lt;li&gt;This follows from the dimension of $A-BD^{-1}C$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Simplifying further gives us $(\sum_{i=1}^n x_i^n)(1+Q)^{m-n+1} = \det(N)$.
&lt;ul&gt;
&lt;li&gt;Using the fact that $\det(M)=f$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This gives us the bound, provided we show that the constant part of $N$ at position $0,0$ is zero and one on the diagonal.&lt;&#x2F;li&gt;
&lt;li&gt;I am skipping this part.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>A Short Overview of Communication Complexity for Algorithms Designers (Reading Group)</title>
        <published>2020-04-01T16:32:00+00:30</published>
        <updated>2020-04-01T16:32:00+00:30</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2020/communication-complexity-reading-group/"/>
        <id>https://narfinger.github.io/posts/2020/communication-complexity-reading-group/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2020/communication-complexity-reading-group/">&lt;h1 id=&quot;communication-complexity&quot;&gt;Communication Complexity&lt;&#x2F;h1&gt;
&lt;p&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1509.06257&quot;&gt;Communication Complexity for Algorithm Designers&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h1 id=&quot;communication-complexity-basics-based-on-chapter-4&quot;&gt;Communication Complexity Basics (Based on Chapter 4)&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Alice and Bob, have $x\in {0,1}^a$ and $y\in {0,1}^b$ both as private information.&lt;&#x2F;li&gt;
&lt;li&gt;Both want to communicate to figure out a function $f:{0,1}^{a+b}\rightarrow {0,1}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;one-way-communication-protocol&quot;&gt;One Way Communication Protocol&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Alice computes $A(x)$ and sends it to Bob for a function $A:{0,1}^a\rightarrow {0,1}^m$.&lt;&#x2F;li&gt;
&lt;li&gt;Bob then decides by computing $B(y,A(x))$.&lt;&#x2F;li&gt;
&lt;li&gt;Alice and Bob do not have a computation bound.&lt;&#x2F;li&gt;
&lt;li&gt;The one way complexity of a function is the minimum over all protocols, worst case number of bits used by any one-way protocol that decides $f$ (remember, $A$, $B$ can be randomized).&lt;&#x2F;li&gt;
&lt;li&gt;I.e., $\min_{ P\text{ protocol}} \max_{x\in {0,1}^a, y\in {0,1}^b} \lvert A(x)\rvert$ for all correct protocols $A(x)$. Similar definition for two-way communication.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;disjointness-problem&quot;&gt;Disjointness Problem&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Let the Universe be $[n]$ and Alice, Bob having vectors $x,y$ being characteristic vectors of sets of size $k$.&lt;&#x2F;li&gt;
&lt;li&gt;I.e., $[1,0,0,1]= {x_1,x_4}$ vs $[1,1,1,0] = { x_1, x_2, x_3}$.&lt;&#x2F;li&gt;
&lt;li&gt;Accept if $S_x\cap S_y=\emptyset$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;deterministic-one-way-communication-complexity-for-disjointness&quot;&gt;Deterministic One-way Communication Complexity for Disjointness&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Every deterministic one-way protocol for disjointness has $n$ has worst-case communication complexity.&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;Consider Alice only sending $n-1$ bits.&lt;&#x2F;li&gt;
&lt;li&gt;Now let us look at the set $S={ y\mid y=A(x) \text{ for any } x}$&lt;&#x2F;li&gt;
&lt;li&gt;The size of this is obviously $2^{n-1}$.&lt;&#x2F;li&gt;
&lt;li&gt;By pigeonhole principle, there are two distinct inputs where Alice sends the same message.&lt;&#x2F;li&gt;
&lt;li&gt;As $x_1,x_2$ differ in at least one bit, Bob can have a set that is compatible with $x_1$ but not $x_2$ violating the correctness of the protocol.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;probabilistic-one-way-communication-complexity-for-disjointness&quot;&gt;Probabilistic One-way Communication Complexity for Disjointness&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Public coins are both visible by Alice and Bob at the same time and don&#x27;t contribute to the communication.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Private coins where Alice and Bob have a private pool.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Public coins are strictly more powerful.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Public coin protocols are equivalent to distributions over deterministic protocols.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Error constants and one vs two-sided errors follow with similar definitions as from normal complexity theory.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Every randomized protocol that decides disjointness with probability $2&#x2F;3$ correctly uses $\Omega(n)$ communication.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Proof:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;[Yao Lemma]: Let $D$ be a distribution over the space of inputs $(x,y)$. Suppose that every deterministic one-way protocol cost at least $k$  with $\Pr[P\text{ is wrong on } (x,y)]\leq \varepsilon$. Then every public coin randomized protocol with error $\varepsilon$ has communication cost at least $k$.&lt;&#x2F;li&gt;
&lt;li&gt;Proving the lemma:
&lt;ul&gt;
&lt;li&gt;Let $R$ be a randomized protocol that uses less than $k$ communication cost.&lt;&#x2F;li&gt;
&lt;li&gt;Then $R$ is a distribution of deterministic protocols $P_1,\dots, P_s$, each with communication cost less than $k$ and some error probability.&lt;&#x2F;li&gt;
&lt;li&gt;Assume every $P_i$ has error larger than $\varepsilon$, then no matter the distribution, $R$ would have error probability higher than $\varepsilon$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence there exists an $i$ such that $P_i$ has error probability less than $\varepsilon$ and it uses less than $k$ communication.&lt;&#x2F;li&gt;
&lt;li&gt;This is a contradiction to the assumption.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;normal-communication&quot;&gt;Normal Communication&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Matrix view of input&#x2F;output behavior $M(f)$.
&lt;ul&gt;
&lt;li&gt;Let us look in the following at Disjointness with the rows and columns being $\emptyset, { x_1}, {x_2}, {x_1, x_2}$ for $X$ and $Y$ respectively.&lt;&#x2F;li&gt;
&lt;li&gt;$\begin{pmatrix} 1&amp;amp; 1&amp;amp; 1&amp;amp; 1\ 1&amp;amp; 0&amp;amp; 1&amp;amp; 0\ 1&amp;amp; 1&amp;amp; 0&amp;amp; 0\ 1&amp;amp; 0&amp;amp; 0&amp;amp; 0&amp;amp;\end{pmatrix}$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Rectangles, i.e., take $X,Y$, chose subsets $A\subseteq X$ of rows and $B\subseteq Y$ of columns such that all $(x,y)\in A\times B$ have the same value (monochromatic).&lt;&#x2F;li&gt;
&lt;li&gt;These Rectangles do not need to be continuous!&lt;&#x2F;li&gt;
&lt;li&gt;Theorem: Let $f$ be a function such that every partition into monochromatic rectangles requires at least $t$ rectangles. Then the deterministic communication complexity is at least $\log t$.
&lt;ul&gt;
&lt;li&gt;Proof: A deterministic protocol of complexity $\log t$ can only have $t$ many different transcripts.&lt;&#x2F;li&gt;
&lt;li&gt;It has to partition the sets into rectangles, as otherwise there would be a non-monochromatic rectangle where the protocol would make a mistake.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Corollary: Every covering of $M(f)$ by monochromatic rectangles requires at least $t$ rectangles, then the deterministic communication complexity is at least $\log t$.&lt;&#x2F;li&gt;
&lt;li&gt;Note, $\log r$ where $r$ is the rank is a lower bound for the communication complexity but unknown if it is an upper bound for the complexity.&lt;&#x2F;li&gt;
&lt;li&gt;Examples:
&lt;ul&gt;
&lt;li&gt;Equality is the identity matrix.&lt;&#x2F;li&gt;
&lt;li&gt;$\begin{pmatrix} 1&amp;amp; 0&amp;amp; 0&amp;amp; 0&amp;amp;\ 0&amp;amp; 1&amp;amp; 0&amp;amp; 0\ 0&amp;amp; 0&amp;amp; 1&amp;amp; 0\ 0&amp;amp; 0&amp;amp; 0&amp;amp; 1\end{pmatrix}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Disjointness has $\log \binom n k = k\log n&#x2F;k$ as there are $\binom n k$ sets for a universe of size $n$ and subsets of size $k$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;randomized-disjointness&quot;&gt;Randomized Disjointness&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Theorem: There exists a distribution such that Disjointness has communication complexity at least $\Omega(k)$$.&lt;&#x2F;li&gt;
&lt;li&gt;What is the distribution?
&lt;ul&gt;
&lt;li&gt;Take uniform distribution, the chance that $f(x,y)=1$ is $(3&#x2F;4)^n$, hence, a algorithm that outputs the constant 1 has high success probability. Hence, accept and reject cases need constant probabilities.&lt;&#x2F;li&gt;
&lt;li&gt;The inputs need to be distributed to not have significantly less than $\log n$ information content per input as otherwise the input can be send.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Distribution:
&lt;ul&gt;
&lt;li&gt;With probability $3&#x2F;4$: $(x,y)$ is chosen uniformly at random subject to: $x,y$ have exactly $n&#x2F;4$ ones and there &lt;em&gt;is no&lt;&#x2F;em&gt; index such that $x_i=y_i=1$.&lt;&#x2F;li&gt;
&lt;li&gt;With probability $1&#x2F;4$: $(x,y)$ is chosen uniformly at random subject to: $x,y$ have exactly $n&#x2F;4$ ones and there &lt;em&gt;is&lt;&#x2F;em&gt; an index such that $x_i=y_i=1$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Almost monochromatic 1 rectangles $R$ with respect to distribution $D$:
&lt;ul&gt;
&lt;li&gt;$\Pr[(x,y)\in R\text{ and } f(x,y)=0] \leq 8\varepsilon \Pr[(x,y)\in R\text{ and } f(x,y)=1]$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Show that an almost chromatic rectangle contains at most $2^{-c}$ mass of the distribution where $c$ is as large as possible.&lt;&#x2F;li&gt;
&lt;li&gt;Proof not given.&lt;&#x2F;li&gt;
&lt;li&gt;There is also a protocol that achieves this:
&lt;ul&gt;
&lt;li&gt;$Z_1,\dots$ uniform random subsets.&lt;&#x2F;li&gt;
&lt;li&gt;Send: smallest index such that $X\subseteq Z_i$ for both.&lt;&#x2F;li&gt;
&lt;li&gt;Discard elements that are not in the $Z_i$ you got.&lt;&#x2F;li&gt;
&lt;li&gt;Repeat until empty set.&lt;&#x2F;li&gt;
&lt;li&gt;Cut off communication at some probability related point.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;communication-complexity-datastructures-chapter-6&quot;&gt;Communication Complexity Datastructures (Chapter 6)&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;The main point of this section will be to show Datastructure Lower Bounds for $\varepsilon$-Gap Hamming in the Cell Probe Model.&lt;&#x2F;li&gt;
&lt;li&gt;Nearest Neighbor:
&lt;ul&gt;
&lt;li&gt;Given points $S={x_1,\dots,x_n}$ in the hamming cube $H^d={0,1}^d$ ($d$ roughly $\Omega(\sqrt{n})$).&lt;&#x2F;li&gt;
&lt;li&gt;Build a structure $D$ such that: Given a point $x\in H^d$ find the closest point in $S$ to $x$ using $D$.&lt;&#x2F;li&gt;
&lt;li&gt;This problem can be transferred to other metric spaces.&lt;&#x2F;li&gt;
&lt;li&gt;Approximation problem where the distance between the real point and the point returned is $l(q,p)\leq (1+\varepsilon)l(q,p)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;varepsilon-gap-hamming&quot;&gt;$\varepsilon$-Gap Hamming&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Specialization of Nearest Neighbor.&lt;&#x2F;li&gt;
&lt;li&gt;$\varepsilon$-Gap Hamming: Decide if the hamming distance $l(x,y)$ is at most $L$ or at least $(1+\varepsilon)L$ for some input $L$.&lt;&#x2F;li&gt;
&lt;li&gt;A communication protocol for this problem:
&lt;ul&gt;
&lt;li&gt;Sample a random string $r_1,\dots,r_s$, $r_i\in { 0,1}^d$ where $r_{i,j}=1$ with probability $\frac{1}{2L}$.&lt;&#x2F;li&gt;
&lt;li&gt;Alice sends $h=&amp;lt; x,r_1&amp;gt;\mod 2, \dots, &amp;lt;x,r_s&amp;gt;\mod 2$.&lt;&#x2F;li&gt;
&lt;li&gt;Bob compares $h=&amp;lt;y,r_1&amp;gt;\mod 2,\dots, &amp;lt;y,r_s&amp;gt;\mod 2$ and accepts if it differs only in a small number of coordinates.&lt;&#x2F;li&gt;
&lt;li&gt;Intuitively this is close to testing equality, except with a bias for the testing string to be zero, i.e., ignore certain errors.
&lt;ul&gt;
&lt;li&gt;If $x,y$ differ in only a single bit, the probability for uniformly $r$ would be $1&#x2F;2$ to reject.&lt;&#x2F;li&gt;
&lt;li&gt;With every choice being $\frac{1}{2L}$, we are much more likely to produce zeroes where and hence, not recognize this.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;The protocol has two-sided error (because of the &quot;at most $L$&quot;).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Proof:
&lt;ul&gt;
&lt;li&gt;See the random process in a different light.&lt;&#x2F;li&gt;
&lt;li&gt;Select relevant coordinate with probability $1&#x2F;L$ and for relevant coordinates choose uniformly at random between $0$ and $1$.&lt;&#x2F;li&gt;
&lt;li&gt;If $l(x,y)=\Delta$, then:&lt;&#x2F;li&gt;
&lt;li&gt;$\Pr_j[\langle r_j,x\rangle \mod 2 \not\equiv \langle r_j,y\rangle\mod 2] = 1&#x2F;2 \cdot \left(1- \left(1-\frac{1}{L}\right)^\Delta\right)$.&lt;&#x2F;li&gt;
&lt;li&gt;i.e., at least one of the $\Delta$ coordinates is chosen (it is not true that all are not chosen) and then $r_i$ is chosen such that it recognizes the difference with probability $1&#x2F;2$.&lt;&#x2F;li&gt;
&lt;li&gt;Now what is the difference if $\Delta \geq (1+\varepsilon)L$?&lt;&#x2F;li&gt;
&lt;li&gt;$\Pr_j [\langle r_j,x\rangle \mod 2 \not\equiv \langle r_j,y \rangle \mod 2] = 1&#x2F;2 \left( 1-\frac{1}{L}\right)^L\left(1- \left(1-\frac{1}{L}\right)^{\varepsilon L}\right)$ by plugging $\Delta=(1+\varepsilon)L$.&lt;&#x2F;li&gt;
&lt;li&gt;Now by $1-x\in [e^{-2x}, e^x]$ for $x\in [0,1]$ we can bound this by&lt;&#x2F;li&gt;
&lt;li&gt;$\geq 1&#x2F;2 \cdot e^{\frac{-2L}{L}} \cdot \left(1- e^{\frac{\varepsilon  L}{L}}\right)$.&lt;&#x2F;li&gt;
&lt;li&gt;$\geq \frac{1}{2e^2}(1-e^{-\varepsilon})$.&lt;&#x2F;li&gt;
&lt;li&gt;This is now constant.&lt;&#x2F;li&gt;
&lt;li&gt;Let $t$ be the probability that $\langle r_i,x\rangle \mod 2 \not\equiv \langle r_i,y\rangle \mod 2$.&lt;&#x2F;li&gt;
&lt;li&gt;So if $l(x,y)\leq \Delta$, we expect $ts$ many random inner products to be different while if $l(x,y)\geq (1+\varepsilon)\Delta$ then at least $(t+O(\varepsilon))s$ to be different.&lt;&#x2F;li&gt;
&lt;li&gt;Chernoff now implies the following:&lt;&#x2F;li&gt;
&lt;li&gt;If the distance is less than $L$ between $x,y$ then the distance of the resulting vectors is at most $(t+1&#x2F;2 \cdot h(\varepsilon))s$&lt;&#x2F;li&gt;
&lt;li&gt;If the distance is greater than $(1+\varepsilon)L$ between $x,y$ then the distance of the resulting vectors is at least $(t+1&#x2F;2 \cdot h(\varepsilon))s$&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;lower-bounds-via-asymmetric-communication-complexity&quot;&gt;Lower Bounds via Asymmetric Communication Complexity&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Cell Probe model:
&lt;ul&gt;
&lt;li&gt;Computation Model, so we can prove lower bounds against this model for some problems.&lt;&#x2F;li&gt;
&lt;li&gt;$D:{0,1}^n \times {0,1}^* \rightarrow {0,1}^{s w}$&lt;&#x2F;li&gt;
&lt;li&gt;Store a database $D$ to answer a set of Queries $Q$ that is known up front. Store $D$ as $s$ cells of $w$ bits.&lt;&#x2F;li&gt;
&lt;li&gt;Every query algorithm gets the content of cells he specifies.&lt;&#x2F;li&gt;
&lt;li&gt;Answer every query in $Q$ correctly.&lt;&#x2F;li&gt;
&lt;li&gt;Query Space (something like this): $\max_x \max_Q \log_w |D(x,Q)|$.&lt;&#x2F;li&gt;
&lt;li&gt;Every query is if $q\in D$, hence $\log Q$ is the trivial upper bound.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Index Problem:
&lt;ul&gt;
&lt;li&gt;Alice has an $i\in [n]$ and Bob $y\in {0,1}^n$. The question is to compute $y_i$.&lt;&#x2F;li&gt;
&lt;li&gt;Every randomized communication protocol for index has either Alice send at least $\delta \log n$ bits or Bob send at least $n^{1-2\delta}$ bits, both in the worst case.&lt;&#x2F;li&gt;
&lt;li&gt;Miltersen Lemma: If $M(f)$ has at least $v$ columns that have at least $u$ 1-inputs and there is a deterministic protocol that computes $f$ and Alice, Bob send at most $a,b$ bits respectively. Then $M(f)$ has a 1-rectangle $A\times B$ with $\lvert A\rvert \geq u&#x2F;2^a$ and $\lvert B\rvert \geq v&#x2F;2^{a+b}$.&lt;&#x2F;li&gt;
&lt;li&gt;A datastructure with query time $t$, space $s$, word size $w$ induces a communication protocol for INDEX in which Alice sends $t\log s$ bits and Bob sends at most $tw$ bits.
&lt;ul&gt;
&lt;li&gt;Bob builds the datastructure, Alice queries it.&lt;&#x2F;li&gt;
&lt;li&gt;Alice makes $t$ queries with everything an cell in the database.&lt;&#x2F;li&gt;
&lt;li&gt;Bob answers the $t$ queries with the content of the cells of size $w$.&lt;&#x2F;li&gt;
&lt;li&gt;If Alice can afterwards decide INDEX, then the communication protocol worked.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;$(k,l)$ Disjointness:
&lt;ul&gt;
&lt;li&gt;Alice has set of size $k$ and Bob of size $l$ from a common universe and they need to decide if the sets are disjoint.&lt;&#x2F;li&gt;
&lt;li&gt;Solving $(1&#x2F;\varepsilon^2, n)$-Disjointness on a Universe of size $2n$ has either Alice send at least $\delta&#x2F;\varepsilon^2 \log n$ bits or Bob send at least $n^{1-2\delta}$ bits for large enough constant $\delta$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Finding hardness of Gap-Hamming in the Cell probe model via reduction to $(1&#x2F;\varepsilon,n)$-Disjointness.
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I.e., If we solve Gap-Hamming, we solve $(1&#x2F;\varepsilon,n)$-Disjointness.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Nearest Neighbor:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Given points $S={x_1,\dots,x_n}$ in the hamming cube $H^d={0,1}^d$ ($d$ roughly $\Omega(\sqrt{n})$).&lt;&#x2F;li&gt;
&lt;li&gt;Build a structure $D$ such that given a point $x\in H^d$ find the closest point in $S$ to $x$ using $D$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;$(1&#x2F;\varepsilon,n)$-Disjointness: Are sets disjoint with size $1&#x2F;\varepsilon$ and $n$.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Solve $(1&#x2F;\varepsilon,n)$-Disjointness with Gap Hamming&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Easy reduction:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Map to $2n$ dimensional hypercube ${0,1}^{2n}$.&lt;&#x2F;li&gt;
&lt;li&gt;Alice has a set of size $1&#x2F;\varepsilon$ from universe of dimension $2n$.&lt;&#x2F;li&gt;
&lt;li&gt;Alice maps her input set $S$ to the characteristic vector in ${0,1}^{2n}$.&lt;&#x2F;li&gt;
&lt;li&gt;Bob maps his input set $T$ to the point set ${ e_i\mid i\in T}$  where $e_i$ is the characteristic vector of the singleton set.&lt;&#x2F;li&gt;
&lt;li&gt;If $S,T$ are disjoint then the query has distance $1&#x2F;\varepsilon +1$ distance from every point.&lt;&#x2F;li&gt;
&lt;li&gt;If they are not disjoint, there exists a point that has distance at most $1&#x2F;\varepsilon -1$.&lt;&#x2F;li&gt;
&lt;li&gt;Both are easy to see. Remember that $\lvert S\rvert = 1&#x2F;\varepsilon$, i.e., Alice has a vector of hamming weight $1&#x2F;\varepsilon$.&lt;&#x2F;li&gt;
&lt;li&gt;Having overlap, means that there exists an $e_i$ where the corresponding value is also 1. Looking at the distance, we have $\sum_{i\in S} 1\leq \lvert S\rvert -1 = 1&#x2F;\varepsilon -1$.&lt;&#x2F;li&gt;
&lt;li&gt;Thus we reduce to Gap-Hamming with $1&#x2F;\varepsilon+1$ vs $1\geq 1&#x2F;\varepsilon-1$ (notice that this is the smallest increase, hence it holds for all reasonable gaps).&lt;&#x2F;li&gt;
&lt;li&gt;If we could decide Gap-Hamming in Cell Probe model with these approximation with $w$ word size, $s$ space and $t$ queries then we would have a $t\log s + tw$ communication protocl.
&lt;ul&gt;
&lt;li&gt;This is just Alice queries Bob who has the datastructure $t$ times with cell described by $\log s$.&lt;&#x2F;li&gt;
&lt;li&gt;Bob answers $t$ queries with the content of the cell of size $w$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;As $(1&#x2F;\varepsilon,n)$-Disjointness communication has lower bounds of $\delta&#x2F;\varepsilon \log n$ and $n^{1-2\delta}$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, $t\log s\geq \delta&#x2F;\varepsilon \log n$ and $tw\geq n^{1-2\delta}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Hardness of high dimensional Gap-Hamming is not very interesting.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Lemma 6.6:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;There exists a randomized function $f$ from ${0,1}^{2n}\rightarrow {0,1}^d$ such that for every set $P$ of $n$ points and query $q$ produced by the reduction above, then with probability at least $1-1&#x2F;n$:&lt;&#x2F;li&gt;
&lt;li&gt;If the nearest neighbor distance between $q$ and $P$ is $1&#x2F;\varepsilon +1$ then the nearest neighbor distance between $f(q)$ and $f(P)$ is at most $\alpha$.&lt;&#x2F;li&gt;
&lt;li&gt;If the nearest neighbor distance between $q$ and $P$ is at most $1&#x2F;\varepsilon -1$ then the nearest neighbor distance between $f(q)$ and $f(P)$ is at most $\alpha(1+h(\varepsilon))$.&lt;&#x2F;li&gt;
&lt;li&gt;This map takes $d=\Theta(\varepsilon^{-2}\log n)$ and random inner products with $2n$ bit vectors.&lt;&#x2F;li&gt;
&lt;li&gt;In essence, this lemma allows us to reduce the dimension of the easy reduction with some probability.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Corollary: Every lower bound for $(1&#x2F;\varepsilon,n)$-Disjointness carries over to the Query-Database problem for the $(1+\varepsilon)$ approximate Nearest Neighbor problem in $d=\Omega(\varepsilon^{-2} \log n)$.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Corollary: Every datastructure for $(1+\varepsilon)$-approximate nearest neighbor with query time $t=\theta(1)$ and word size $O(n^{1-\delta})$ uses space $s=n^{\Omega(\varepsilon^{-1})}$.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Plugging this into our equations gives roughly:
&lt;ul&gt;
&lt;li&gt;$c\log s \geq c&#x27;&#x2F;\varepsilon \log n$ and $cn^{1-\delta}\geq n^{1-2\delta}$.&lt;&#x2F;li&gt;
&lt;li&gt;This gives us a bound of $s\geq n^{c&#x27;&#x2F;\varepsilon}$, what the corollary says.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This can be refined to $s=n^{\Omega(\varepsilon^{-2})}$ with a slightly better reduction.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Overview over the real $	au$-conjecture</title>
        <published>2018-06-21T00:00:00+00:00</published>
        <updated>2018-06-21T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://narfinger.github.io/posts/2018/tau-conjecture-overview/"/>
        <id>https://narfinger.github.io/posts/2018/tau-conjecture-overview/</id>
        
        <content type="html" xml:base="https://narfinger.github.io/posts/2018/tau-conjecture-overview/">&lt;h1 id=&quot;an-overview-over-the-real-tau-conjecture&quot;&gt;An Overview over the real $\tau$-conjecture&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;references&quot;&gt;References:&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;doi.org&#x2F;10.1007&#x2F;s00037-009-0260-x&quot;&gt;Buergisser - On Defining integers and proving arithmetic circuit lower bounds&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1004.4960&quot;&gt;Koiran - Shallow circuits with High-Powered Inputs&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;http:&#x2F;&#x2F;users.math.cas.cz&#x2F;~hrubes&#x2F;PDFs&#x2F;RealTau.pdf&quot;&gt;Hrubes - On the real $\tau$-conjecture and the distribution of complex roots&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1205.1015&quot;&gt;Koiran,Portier,Tavenas - A Wronskian Approach to the real $\tau$-conjecture&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1308.2286&quot;&gt;Koiran,Portier,Tavenas,Thomasse - A $\tau$-conjecture for Newton Polygons&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a rel=&quot;noopener&quot; target=&quot;_blank&quot; href=&quot;https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1806.00417&quot;&gt;Briquel, Buergisser - The real tau-conjecture is true on average&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;tau-conjecture&quot;&gt;$\tau$-conjecture&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Conjecture: The number of integer roots of a univariate polynomial $f$ computed by a constant free circuit of size s is bounded by $s^{O(1)}$.&lt;&#x2F;li&gt;
&lt;li&gt;Proving the conjecture shows that $P_{\mathbb{C}} \neq NP_{\mathbb{C}}$.&lt;&#x2F;li&gt;
&lt;li&gt;Proving the conjecture shows that $VP\neq VNP$.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem: computing the family $(n!)$ is hard (exponential in $\log n$) iff the $\tau$-conjecture is true. (Buergisser)&lt;&#x2F;li&gt;
&lt;li&gt;Number of real roots of Chebyshev polynomials is exponential in the circuit size (and other examples).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;conjecture&quot;&gt;Conjecture&lt;&#x2F;h2&gt;
&lt;p&gt;Let $f(x)=\sum_{i=1}^k \prod_{j=1}^m f_{i,j}(x)$ with $f_{i,j}$ being $t$-sparse. then the number of real roots is bounded by some polynomial in $mkt$ (all polynomials are univariate).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;a-note-on-multiplicities&quot;&gt;A note on multiplicities&lt;&#x2F;h2&gt;
&lt;p&gt;Hrubes basically shows that it does not matter if we count multiplicities or not as both imply each other (via some construction with replacing x ith $xe^{i}$).&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$S(\alpha,\beta)= { re^{i\phi}\in \mathbb{C}\mid r&amp;gt;0, \beta&amp;lt;\phi&amp;lt;\alpha}$.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Conjecture 1: $f(x)=\sum_{i=1}^k \prod_{j=1}^m f_{i,j}(x)$ with $f_{i,j}$ being $t$-sparse, the number of real roots &lt;em&gt;without multiplicity&lt;&#x2F;em&gt; is poly$(mkt)$.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Conjecture 2: $f(x)=\sum_{i=1}^k \prod_{j=1}^m f_{i,j}(x)$ with $f_{i,j}$ being $t$-sparse, the number of real roots &lt;em&gt;with multiplicity&lt;&#x2F;em&gt; is poly$(mkt)$.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;Conjecture 3: For every $0&amp;lt;\alpha -\beta&amp;lt;2\pi$, $f(x)=\sum_{i=1}^k \prod_{j=1}^m f_{i,j}(x)$ with $f_{i,j}$ being $t$-sparse, $\lvert N_{\alpha, \beta}(f) -\frac{\alpha-\beta}{2\pi} n\rvert \leq mkt^{O(1)}$ where $N_{\alpha, \beta}(f)$ is the number of roots of $f$ of the form $re^{i\phi}$ (the angles of the roots are distributed uniformly, expect an error linearly depending on the terms of $f$).&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;2-&amp;gt;1: Obvious.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;3-&amp;gt;2:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Look at $re^{i\phi}$, $r&amp;gt;0$ a root with multiplicity $m$.&lt;&#x2F;li&gt;
&lt;li&gt;Look at Sector $S(\phi+\pi&#x2F;n, \phi - \pi&#x2F;n)$.&lt;&#x2F;li&gt;
&lt;li&gt;Assuming $f(0)\neq 0$. The number of roots in $S$ are at most $\lvert N_{\alpha,\beta}(f) - \phi+\pi&#x2F;n - (\phi - \pi&#x2F;n)\rvert = \lvert N_{\alpha,\beta} -1\vert \leq (kmt)^c+1$&lt;&#x2F;li&gt;
&lt;li&gt;Hence the multiplicity is bounded by $s^c+1$ and hence the conjecture follows as there are $2n$ sectors.&lt;&#x2F;li&gt;
&lt;li&gt;If $f(0)=0$ repeat this argument with $f(0+\varepsilon)$ for a small $\varepsilon$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;1-&amp;gt;3:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Proposition 3.1: Let $f$ be a polynomial with degree $n$ and the real part of $f(0)\neq 0$. Then for every $0&amp;lt;\alpha -\beta &amp;lt;2\pi$, $\lvert N_{\alpha,\beta}(f) -\frac{\alpha -\beta }{2\pi}n\rvert \leq M(f)+1&#x2F;2$ where $M(f) = \max_{\alpha \in [0,2\pi] M_\alpha(f)}$ and $M_\alpha(f)$ the number of distinct possible roots of of the real polynomial $\mathcal{R}(f(xe^{i\alpha}))$. ($\mathcal{R}$ is the real part.)&lt;&#x2F;li&gt;
&lt;li&gt;Proposition 3.3: Let $f=\sum_{i=1}^k \prod_{j=1}^m f_{i,j}$ where each $f_{i,j}$ is $t$-sparse. Then $\mathcal{R}(f) = \sum_{i=1}^{k(m+1)} \prod_{j=1}^m g_{i,j}$ where $g_{i,j}$ are $t$-sparse (This is shown by a standard interpolation argument).&lt;&#x2F;li&gt;
&lt;li&gt;By Proposition 3.1 we can look at the real roots of $f(xe^{i\alpha})$.&lt;&#x2F;li&gt;
&lt;li&gt;By Proposition 3.3, $\mathcal{R}(f(xe^{i\alpha}))$ has the form of Conjecture 1, giving us $(k(m+1)(m+1))^O(1)$ many roots.&lt;&#x2F;li&gt;
&lt;li&gt;This shows Conjecture 3.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;koiran-shallow-circuits-with-high-powered-inputs&quot;&gt;Koiran - Shallow circuits with High-Powered Inputs&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;theorem&quot;&gt;Theorem&lt;&#x2F;h2&gt;
&lt;p&gt;If the conjecture is true then the permanent is not in $VP_0$.&lt;&#x2F;p&gt;
&lt;p&gt;In the following $VP_0$ and $VNP_0$ are the known classes, except that we only allow constants from ${-1,0,+1}$ to be used.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;proof&quot;&gt;Proof&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;part-1&quot;&gt;Part 1&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Def: $SPS_{s,e}$ all $\Sigma\Pi\Sigma$ circuits that have at most  $s$ monomials, coefficients of bit size $2^e$ and $f_{i,j}$ have degree $e$.&lt;&#x2F;li&gt;
&lt;li&gt;We assume the following conjecture: $SPS_{s,e}$ has at most $(s+\log e)^c$ many integer roots.
&lt;ul&gt;
&lt;li&gt;This is clearly weaker than the real $\tau$ conjecture.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Let $s=n^{O(\sqrt{n} \log n)}, e=2^{O(n)}$.&lt;&#x2F;li&gt;
&lt;li&gt;Assume the following statement: perm $\in VP_0$ then $g_n = \prod_{i=1}^{2^n} x -i$, $2^{p(n)}g_n\in SPS_{s,e}$ (we will show this statement later).&lt;&#x2F;li&gt;
&lt;li&gt;Let $H_m$ be the roots of $x-i$ for all $i\leq m$&lt;&#x2F;li&gt;
&lt;li&gt;Notice that $H_{2^n}$ is a hitting set for $SPS_{s,e}$ for $m\leq 2^{o(n)}$ for large enough $n$.
&lt;ul&gt;
&lt;li&gt;Here we use our conjecture! The conjecture says, any such $SPS_{s,e}$ circuit has at most $(s+\log e)^c$ many roots.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, it has $m=(2^{\sqrt{n} \log^2 n} + O(n))^c &amp;lt; 2^{o(n)}$ many roots by our conjecture.&lt;&#x2F;li&gt;
&lt;li&gt;Hence an set of $&amp;gt;m$ numbers is a hitting set.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Hence $H_m$ is a hitting set for $2^{p(n)}g_n$.&lt;&#x2F;li&gt;
&lt;li&gt;But $g_n$ vanishes on $H$ and is not equal zero.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, the implication: perm$\in VP_0 \Rightarrow 2^{p(n)} g_n \in SPS_{s,e}$ has to be false.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;part-2&quot;&gt;Part 2&lt;&#x2F;h3&gt;
&lt;p&gt;Ingredients for Part 2. In the following, $s=n^{O(\sqrt n \log n)}$ and $e=2^{O(n)}$.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Lemma 2: If perm $\in VP_0$ then $CH&#x2F;poly = P&#x2F;poly$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 1: Valiant&#x27;s Criterion: If $f(j,n)\in GapP&#x2F;poly$ then $\sum_{j\in {0,1}^n} f(j,n)x_1^{j_1}\cdots x_n^{j_n} \in VNP_0$.&lt;&#x2F;li&gt;
&lt;li&gt;Theorem 1: If perm $\in VP_0$ then for all $(f_n)\in VNP$, $(2^{p(n)}f_n)\in VP_0$.&lt;&#x2F;li&gt;
&lt;li&gt;Proposition 1: Let $f_n(X,Z)\in VP_0$ then $f_n(x^{2^0},\dots, x^{2^{cn-1}},z^{2^0},\dots,z^{2^{cn-1}})$ has $SPS_{s,e}$.&lt;&#x2F;li&gt;
&lt;li&gt;Notice that for our polynomial $g_n$, the degrees and coefficient bit size are bounded by $2^n, 2^{2^{(c+1)n}}$ respectively and the coefficients are computable in $CH&#x2F;poly$. Hence, the following works.&lt;&#x2F;li&gt;
&lt;li&gt;See $g_n$ as $g_n=\sum_\alpha a(n,\alpha)x^\alpha$ and expand $a$ into binary, resulting in the polynomial:&lt;&#x2F;li&gt;
&lt;li&gt;$h_n(x_1,\dots,x_{cn},z_1,\dots,z_{cn})$ such that $h_n(x^{2^0}, \dots,x^{2^{cn-1}},2^{2^0},\dots,2^{2^{cn-1}})=g_n$.&lt;&#x2F;li&gt;
&lt;li&gt;Let us denote the bits of $a(n,\alpha)$ by $a_i(n,\alpha)$.&lt;&#x2F;li&gt;
&lt;li&gt;$a_i(n,\alpha)$ is computable by Lemma 2 in $GapP&#x2F;poly$. Hence $h_n \in VNP_0$&lt;&#x2F;li&gt;
&lt;li&gt;By Theorem 1, $2^{p(n)}h_n\in VP_0$.&lt;&#x2F;li&gt;
&lt;li&gt;By Proposition 1, $g_n\in SPS_{s,e}$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;comments&quot;&gt;Comments&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;With my understanding, even proving that the roots of a $\Sigma\Pi\Sigma$ circuit are far away would be interesting and show the lower bound&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;koiran-portier-tavenas-a-wronskian-approach-to-the-real-tau-conjecture&quot;&gt;Koiran, Portier, Tavenas - A Wronskian approach to the real $\tau$-conjecture&lt;&#x2F;h1&gt;
&lt;p&gt;Finding upper bounds for the number of roots for
$$
\sum_{i=1}^k \alpha_i \prod_{j=1}^m f_{i,j}^{\beta_{i,j}}
$$
where $f_{i,j}$ are $t$-sparse.&lt;&#x2F;p&gt;
&lt;p&gt;Theorem 12: Such an $f$ has at most $O(t^{\frac{mk^2}{2}})$ roots.&lt;&#x2F;p&gt;
&lt;p&gt;Wronskian:
$$
W(f_1,\dots, f_k) = \det \begin{pmatrix} f_1&amp;amp; \dots&amp;amp; f_k\
\vdots&amp;amp; \ddots&amp;amp; \vdots\
\frac{\partial^{k-1}}{\partial x^{k-1}} f_1&amp;amp;\dots&amp;amp;\frac{\partial^{k-1}}{\partial x^{k-1}} f_k
\end{pmatrix}
$$&lt;&#x2F;p&gt;
&lt;h2 id=&quot;proof-1&quot;&gt;Proof&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;ingredients&quot;&gt;Ingredients&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Theorem 9: Let $f_1,\dots,f_k$ be analytical independent functions then $Z(f_1 + \dots + f_n) \leq k-1 + Z(W_k) + Z(W_{k+1}) + 2\sum_{i=1}^{k-2} Z(W_j)$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 10: Derivative of $f^\alpha$ of order $p$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 11: Take $M$ a set of $t$ monomials and $f_1,\dots, f_s$ be polynomials with monomials in $M$. Take a monomial $P(f_1,f_1^(1),\dots,f_1^{(s-1)}, f_s, \dots, f_s^{(s-1)})$. The number of monomials in $x$ of $P$ is at most $\binom{d+t-1}{t-1}$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 2: Let $f=\sum_{i=1}^t \alpha_i x^{\alpha_i}$ where $\alpha_i$ are pairwise not equal. Then $f$ has at most $t-1$ real roots. [Descarte&#x27;s weak Rule of Signs].&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;theorem-9&quot;&gt;Theorem 9&lt;&#x2F;h3&gt;
&lt;ul&gt;
&lt;li&gt;Let $W_i = W(f_1,\dots,f_i)$, $W_0=1$.&lt;&#x2F;li&gt;
&lt;li&gt;Lemma 22: Let $R_0=f_1 + \dots + f_k$ and $R_{i+1}= \frac{W^2_{i+1}}{W_i} \frac{\partial}{\partial x} \frac{R_i}{W_{i+1}}$. Then $R_{k-1} = W_k$.&lt;&#x2F;li&gt;
&lt;li&gt;Rolle&#x27;s Theorem: Let $f(a)=f(b)$ and continuous and differentiable, then there exists $c$ such that $f&#x27;(c)=0$.&lt;&#x2F;li&gt;
&lt;li&gt;Induction on $i$ with hypothesis: $R_i$ has at least $Z(f_1+ \dots + f_k) - i - Z(W_i) - 2\sum_{j=1}^{i-1} Z(W_j)$ many real roots.&lt;&#x2F;li&gt;
&lt;li&gt;We want to get analyse the roots of $\frac{R_i}{W_{i+1}}$.&lt;&#x2F;li&gt;
&lt;li&gt;Let us define, where $m_x(F)$ is the multiplicity of the root in $F$:
&lt;ul&gt;
&lt;li&gt;$Z_i^+ = #{ x \mid m_x(R_i) &amp;gt; m_x(W_{i+1}) &amp;gt;0 }$.&lt;&#x2F;li&gt;
&lt;li&gt;$Z_i^= = #{ x \mid m_x(R_i) = m_x(W_{i+1}) &amp;gt;0 }$.&lt;&#x2F;li&gt;
&lt;li&gt;$Z_i^- = #{ x \mid 0&amp;lt; m_x(R_i) &amp;lt; m_x(W_{i+1}) }$.&lt;&#x2F;li&gt;
&lt;li&gt;$Z_i^{-0} = #{ x \mid 0= m_x(R_i) &amp;lt; m_x(W_{i+1}) }$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;This list is exhaustive and hence $Z(W_{i+1}) = Z_i^+ + Z_i^= + Z_i^- + Z_i^{-0}$ (as we only look at roots that for $W_{i+1}$).&lt;&#x2F;li&gt;
&lt;li&gt;Let $F$ be the number of zeros of $R_i$. Then&lt;&#x2F;li&gt;
&lt;li&gt;$Z(\frac{R_i}{W_{i+1}}) \geq  F- Z_i^= - Z_i^-$.&lt;&#x2F;li&gt;
&lt;li&gt;We have poles (where the value goes to infinite) at $Z_i^-$, $Z_i^{-0}$.&lt;&#x2F;li&gt;
&lt;li&gt;Rolle&#x27;s Theorem, says: between every two of our zeroes there is a place where the derivated function is zero.&lt;&#x2F;li&gt;
&lt;li&gt;Hence $Z(\frac{\partial}{\partial x}\frac{R_i}{W_{i+1}}) = F-Z_i^= - Z_i^- -1$ but this is not correct. I also have to subtract $Z_i^-+Z_i^{-0}$ as these could match with non-poles on the other size.&lt;&#x2F;li&gt;
&lt;li&gt;Hence the overall is $F-Z_i^= - Z_i^- - 1 - Z_i^- - Z_i^{-0}$.&lt;&#x2F;li&gt;
&lt;li&gt;Now we can figure out the number of roots of $\frac{W^2_{i+1}}{W_i} \partial \frac{R_i}{W_{i+1}}$.&lt;&#x2F;li&gt;
&lt;li&gt;Number of zeroes is just added, hence $(F-Z_i^= - Z_i^- - 1 - Z_i^- - Z_i^{-0}) + Z_i^- - Z(W_i))$&lt;&#x2F;li&gt;
&lt;li&gt;The reason is that by the following argument, we get at least one zero for every $x$ that is in $Z_i^-$. &lt;span style=&quot;color:red&quot;&gt;Is this just an obvious lower bound?&lt;&#x2F;span&gt;&lt;&#x2F;li&gt;
&lt;li&gt;We use the fact that if $0&amp;lt; m_x(R_i) &amp;lt; m_x(W_{i+1})$ then $W_{i+1}^2$ grows faster to zero than $1&#x2F;W_{i+1}$ and hence there is a root at $W_{i+1}^2 \cdot \partial (\frac{R_i}{W_{i+1}})$.&lt;&#x2F;li&gt;
&lt;li&gt;Hence, we get $Z(f_1+ \dots + f_k) - i - Z(W_i) - 2\sum_{j=1}^{i-1} Z(W_j) -Z_i^= - Z_i^- -1 - Z_i^- -Z_i^{-0} + Z_i^- - Z(W_i)$.&lt;&#x2F;li&gt;
&lt;li&gt;Using the equality for $Z(W_{i+1})=Z_i^+ + Z_i^= + Z_i^- + Z_i^{-0}$ i.e., ($-Z(W_{i+1}) + Z_i^+= -Z_i^- -Z_i^= - Z_i^{-0})$ gives us&lt;&#x2F;li&gt;
&lt;li&gt;$Z(f_1 + \dots + f_k) - (i+1) - 2\sum_{j=1}^i Z(W_j) - Z(W_{i+1}) + Z_i^+$ which gives us the required lower bound.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;koiran-portier-tavenas-thomasse-a-tau-conjecture-for-newton-polygons&quot;&gt;Koiran, Portier, Tavenas, Thomasse - A $\tau$-conjecture for Newton Polygons&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Let $f$ be a bivariate polynomial. Then we can identify $X^iY^j$ with a point $(i,j)$. Call this Mon($f$). Now Newt($f$) is the convex hull of all Mon($f$).&lt;&#x2F;li&gt;
&lt;li&gt;Conjecture: Any bivariate polynomial $f=\sum_{i=1}^k\prod_{j=1}^m f_{ij}$ with $f_{ij}$ having at most $t$ monomials. Then the newton polynomial of $f$ has at most $(kmt)^{O(1)}$ edges.&lt;&#x2F;li&gt;
&lt;li&gt;Assume that for some constant $c&amp;lt;2$ the upper bound on the number of edges of the newton polynomial of the form of $f$ is bounded by $2^{(m+\log kt)^c}$ when the product $kmt$ is sufficiently large. Then the permanent is not computable by polynomial size circuits.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;briquel-buergisser-the-real-tau-conjecture-is-true-on-average&quot;&gt;Briquel, Buergisser - The real tau conjecture is true on average&lt;&#x2F;h1&gt;
&lt;ul&gt;
&lt;li&gt;Let $k_1,\dots,k_m$ and $t$ be positive integers. We fix supports $S_{i,j}\subseteq \mathbb{N}$ with $\lvert S_{i,j}\rvert \leq t$ we choose coefficients $u_{i,j,s}$ as independent gaussian random variables with $f_{i,j}= \sum_{s\in S_{i,j}} u_{i,j,s} x^s$ and $f=\sum_{i=1}^m \prod_{j=1}^{k_i} f_{i,j}$. Then the &lt;em&gt;expected&lt;&#x2F;em&gt; number of real zeros of $f$ is bounded by $O(tk_1 + \dots + tk_t)$.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
</feed>
